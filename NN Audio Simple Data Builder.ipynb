{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a long file with clip FT (possibly modified/split, etc.)  transposed and concatenated into a long series of samples\n",
    "\n",
    "It's designed for a process that just grabs a window instead of using a prepared frame (since that creates massive data duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import cmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shared constants and functions\n",
    "%run \"NN Audio Core.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of all zero samples between clips\n",
    "PAD_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_file(data_path, max_samples):\n",
    "    frames_file = data_path + \"\\\\fsamples-C\" + str(SAMPLE_BINS) + \"-\" + str(max_samples)\n",
    "    filename = os.fsdecode(frames_file)\n",
    "    return filename\n",
    "\n",
    "def targets_file(data_path, max_samples):\n",
    "    targets_file = data_path + \"\\\\ftargets-C\" + str(SAMPLE_BINS) + \"-\" + str(max_samples)\n",
    "    filename = os.fsdecode(targets_file)\n",
    "    return filename\n",
    "\n",
    "# Iterate over clean & noisy folders to create frames and targets\n",
    "# Updated to select clips based on difference between clean & noisy versions\n",
    "def create_data(wav_root, data_path, max_samples = 10000, min_diff = 70, max_diff=300, mmap=True):\n",
    "    clean_dir = wav_root + \"\\\\Clean\\\\\"\n",
    "    noisy_dir = wav_root + \"\\\\Noisy\\\\\"\n",
    "    sample_index = 0\n",
    "    if (mmap):\n",
    "        frames = np.memmap(frames_file(data_path, max_samples), mode='w+', dtype=DTYPE, shape=(max_samples,SAMPLE_BINS,INPUT_DEPTH))\n",
    "        targets = np.memmap(targets_file(data_path, max_samples), mode='w+', dtype=OUTPUT_DTYPE, shape=(max_samples,SAMPLE_BINS,OUTPUT_DEPTH))\n",
    "    else:\n",
    "        frames = np.empty(dtype=DTYPE, shape=(max_samples,SAMPLE_BINS,INPUT_DEPTH))\n",
    "        targets = np.empty(dtype=OUTPUT_DTYPE, shape=(max_samples,SAMPLE_BINS,OUTPUT_DEPTH))\n",
    "    file_list = os.listdir(clean_dir)\n",
    "    file_index = 0\n",
    "    while (sample_index < max_samples) and (file_index < len(file_list)) :\n",
    "        file = file_list[file_index]\n",
    "        filename = os.fsdecode(file)\n",
    "        file_index += 1\n",
    "        noisy_ft = get_ft_from_file(noisy_dir + file)\n",
    "        clean_ft = get_ft_from_file(clean_dir + file)\n",
    "        diff = diff_ft(noisy_ft, clean_ft)\n",
    "        if (diff > min_diff) and (diff < max_diff):\n",
    "            new_frames = get_samples_from_ft(noisy_ft)\n",
    "            max_step = min(new_frames.shape[0], max_samples-sample_index)\n",
    "            frames[sample_index:sample_index+max_step,:,:] = new_frames[:max_step,:,:]\n",
    "            new_targets = get_targets_from_ft(clean_ft)\n",
    "            targets[sample_index:sample_index+max_step,:,:] = new_targets[:max_step,:,:]\n",
    "            sample_index += new_targets.shape[0]\n",
    "            if (PAD_SIZE > 0) and (sample_index < max_samples):\n",
    "                pad_width = min(PAD_SIZE, max_samples-sample_index)\n",
    "                frames_pad = np.zeros((pad_width, SAMPLE_BINS,INPUT_DEPTH))\n",
    "                targets_pad = np.zeros((pad_width, SAMPLE_BINS,OUTPUT_DEPTH))\n",
    "                frames[sample_index:sample_index+pad_width,:,:] = frames_pad[:pad_width,:]\n",
    "                targets[sample_index:sample_index+pad_width,:,:] = targets_pad[:pad_width,:]\n",
    "                sample_index += pad_width\n",
    "    print(\"Reached sample # \" + str(min(sample_index, max_samples)))\n",
    "    return frames, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached sample # 100000\n"
     ]
    }
   ],
   "source": [
    "# small test data \"Assets\\\\DataShareArchive\\\\Test\"\n",
    "# 28K \"F:\\\\Audiodata\\\\Train28Spk\"\n",
    "f, t = create_data(\"F:\\\\Audiodata\\\\Train28Spk\", \"f:\\\\Audiodata\", max_samples=100000, min_diff=0.05, max_diff=0.25, mmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To release the files if we need to\n",
    "del f, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
