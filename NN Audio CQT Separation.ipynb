{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NN Audio CQT Separation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ugJNGnNlkTwI",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "import os\n",
        "import time\n",
        "import cmath\n",
        "\n",
        "# This is to force CPU evaluation since we probably train on a bigger GPU than I have\n",
        "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
        "\n",
        "import keras\n",
        "import keras.layers as layers\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "from keras import regularizers\n",
        "from keras import layers\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "#%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4feLoHQPMO2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if we have a GPU\n",
        "import tensorflow as tf\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a0NWhq04kTwN",
        "colab": {}
      },
      "source": [
        "\n",
        "# Constants and settings\n",
        "DTYPE = 'float32'\n",
        "\n",
        "WINDOW_SIZE = 55  # Has to be odd\n",
        "TARGET_COL = WINDOW_SIZE//2\n",
        "\n",
        "# stft values\n",
        "#N_FFT = 1024 # 512 recommended for speech, music typically 2048\n",
        "#FFT_BINS = 513\n",
        "\n",
        "# cqt values\n",
        "HOP_LENGTH = 128 # Required for good round trip quality\n",
        "\n",
        "BINS_PER_OCTAVE = 12 * 5\n",
        "FMIN = librosa.note_to_hz('C1') # Could probably cut further up, but doesn't work in librosa\n",
        "OCTAVES = 8\n",
        "\n",
        "FFT_BINS = OCTAVES * BINS_PER_OCTAVE # function of items below\n",
        "\n",
        "\n",
        "# Shared functions\n",
        "\n",
        "# Idea here is that we operate on magnitude, and will just use phase from the original noisy sample\n",
        "# NOTE that this only seems to work well with stft, not cqt\n",
        "def rebuild_fft(output, original_fft):\n",
        "    vphase = np.vectorize(cmath.phase)\n",
        "    o_phase = vphase(original_fft)\n",
        "    mag = output.T\n",
        "    vrect = np.vectorize(cmath.rect)\n",
        "    return vrect(mag, o_phase)\n",
        "\n",
        "\n",
        "def get_ft(wav):\n",
        "    c = librosa.cqt(wav, hop_length=HOP_LENGTH, fmin=FMIN, n_bins=OCTAVES*BINS_PER_OCTAVE, bins_per_octave=BINS_PER_OCTAVE)\n",
        "    #c = librosa.stft(wav, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
        "    return c\n",
        "\n",
        "def get_ft_from_file(file):\n",
        "    filename = os.fsdecode(file)\n",
        "    wav, rate = librosa.core.load(filename)\n",
        "    return get_ft(wav)\n",
        "\n",
        "def inv_ft(ft):\n",
        "    return librosa.icqt(ft, hop_length=HOP_LENGTH, fmin=FMIN, bins_per_octave=BINS_PER_OCTAVE)\n",
        "    #return librosa.istft(ft, hop_length=HOP_LENGTH)\n",
        "\n",
        "# This is an approximation - much better ways to compare voice quality exist, but this works fine\n",
        "def diff_ft(ft1, ft2):\n",
        "    per_sample = np.sum(abs(ft1-ft2), axis=0)\n",
        "    return np.average(per_sample)\n",
        "\n",
        "# Returns magnitude and phase as x & y on unit circle (for continuous error measurement)\n",
        "def get_samples(file):\n",
        "    wav, rate = librosa.core.load(file)\n",
        "    ft = get_ft(wav)\n",
        "    polar_vect = np.vectorize(cmath.polar)\n",
        "    M, P = polar_vect(ft)\n",
        "    # organized as bins, frames so we need to transpose first two axes to frames, bins\n",
        "    samples = np.empty((M.shape[1],M.shape[0],3))\n",
        "    samples[:,:,0] = M.T \n",
        "    samples[:,:,1] = np.cos(P).T\n",
        "    samples[:,:,2] = np.sin(P).T\n",
        "    return samples \n",
        "\n",
        "def rebuild_cqt(output):\n",
        "    M = output[:,:,0]\n",
        "    R = M * output[:,:,1]\n",
        "    I = M * output[:,:,2] * 1j \n",
        "    cqt = R + I\n",
        "    return cqt.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cPWfsAnkkgxD",
        "outputId": "bb1731a1-17cd-4954-ad99-a83507112a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# If on google colab, run this\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X4ZOOJsSkTwM"
      },
      "source": [
        "Rewriten to use a single stream of data and on the fly creation of batch data\n",
        "\n",
        "TODO\n",
        "* Change name from frames to samples everywhere\n",
        "\n",
        "* Automatic logging of graphs, errors, models etc. for comparison\n",
        "* Add graph of model\n",
        "    from keras.utils import plot_model\n",
        "    plot_model(model, to_file='model.png')\n",
        "\n",
        "* Look for sources of noise that are close to what I want?  Or generate some clips?\n",
        "\n",
        "* Add history error plotting to compare different learning models, topologies, etc.\n",
        "\n",
        "* Why does https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785 only use real component?\n",
        "* Evaluate different representations of complex numbers in terms of learnability\n",
        "\n",
        "* Consider generating custom data for goal - male speakers, low voice, specific sounds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0mgM7ZVjlStg",
        "colab": {}
      },
      "source": [
        "# For local data\n",
        "samples=100000\n",
        "drive_data = \"\"\n",
        "\n",
        "#\"\\\\ftargets-CQT-B\" + str(FFT_BINS) + \"-\"\n",
        "frames = np.memmap(\"f://audiodata//fsamples-CQT-B\" + str(FFT_BINS) + \"-\" +str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 2))\n",
        "targets = np.memmap(\"f://audiodata//ftargets-CQT-B\" + str(FFT_BINS) + \"-\" +str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DPr-t-MTVf_i",
        "colab": {}
      },
      "source": [
        "# Data access for Colab\n",
        "# Move data to VM local drive for reliable access\n",
        "drive_data = '/content/drive/My Drive/Projects/Audio Separation/Data/'\n",
        "os.chdir(drive_data)\n",
        "#print(os.curdir)\n",
        "\n",
        "import shutil\n",
        "samples = 300000\n",
        "frames_file = \"fsamples-CQT-B\" + str(FFT_BINS) + \"-\" + str(samples)\n",
        "targets_file = \"ftargets-CQT-B\"+ str(FFT_BINS) + \"-\" +str(samples)\n",
        "shutil.copy(frames_file, \"/content/\")\n",
        "shutil.copy(targets_file, \"/content/\")\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "#print(os.listdir())\n",
        "\n",
        "# for testing identity mapping : #frames = np.memmap(\"ftargets-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 1))\n",
        "frames = np.memmap(frames_file, mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 3))\n",
        "targets = np.memmap(targets_file, mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ur6yJmzVkTwc",
        "colab": {}
      },
      "source": [
        "# Code to generate input, target, and verification data\n",
        "# From https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, input_array, target_array, batch_size=32, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.input_array = input_array\n",
        "        self.target_array = target_array\n",
        "        self.dim = (WINDOW_SIZE,FFT_BINS) # Input data shape\n",
        "        self.batch_size = batch_size\n",
        "        self.list_IDs = list_IDs  # the set of allowed IDs to use as addresses for frames and target samples\n",
        "        self.n_channels = 3\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size, FFT_BINS, self.n_channels), dtype=DTYPE)\n",
        "\n",
        "        # Generate data\n",
        "        half_win = WINDOW_SIZE // 2\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample & target\n",
        "            X[i,] = self.input_array[ID-half_win:ID+half_win+1,:,:]\n",
        "            y[i] = self.target_array[ID,:,:]\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kJq_FBWlVqiJ",
        "colab": {}
      },
      "source": [
        "# Prepare the generator\n",
        "validation_split = 0.05\n",
        "batch_size = 64\n",
        "\n",
        "# Available IDs\n",
        "all_IDs = np.arange(WINDOW_SIZE//2, frames.shape[0]-WINDOW_SIZE//2)\n",
        "np.random.shuffle(all_IDs)\n",
        "\n",
        "validation_cut = int(np.floor(len(all_IDs) * (1-validation_split)))\n",
        "validation_IDs = all_IDs[validation_cut:]\n",
        "train_IDs = all_IDs[0:validation_cut-1]\n",
        "\n",
        "training_generator = DataGenerator(train_IDs, frames, targets, batch_size=batch_size)\n",
        "validation_generator = DataGenerator(validation_IDs, frames, targets, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kPnHk4p2AIpj",
        "colab": {}
      },
      "source": [
        "# Network building functions\n",
        "def conv_set(depth, kernel, strides, name, input, padding='valid'):\n",
        "  conv = layers.Conv2D(depth, kernel_size=kernel, strides=strides, padding=padding, activity_regularizer=regularizers.l2(L2Reg), use_bias = False, name=name+\"_conv\")(input)\n",
        "  norm = layers.BatchNormalization()(conv)\n",
        "  return layers.LeakyReLU(alpha=ALPHA, name=name+\"_LRelu\")(norm)\n",
        "\n",
        "def pool_set(size, strides, name, input):\n",
        "  pool = layers.MaxPooling2D(pool_size=size, strides=strides, name=name+\"_pool\")(input)\n",
        "  return layers.LeakyReLU(alpha=ALPHA)(pool)\n",
        "\n",
        "\n",
        "# from https://towardsdatascience.com/hitchhikers-guide-to-residual-networks-resnet-in-keras-385ec01ec8ff\n",
        "\n",
        "# TODO make this actually work!!!\n",
        "def res_conv_block(f, filters, name, block, X):\n",
        "  F1, F2, F3 = filters \n",
        "  X_shortcut = X\n",
        "  ## Main path\n",
        "  # First component\n",
        "  X = conv_set(F1, (1,1), (1,1), name+\"_res_conv_\" + block + \"_1\", X)\n",
        "  X = conv_set(F2, (f,f), (1,1), name+\"_res_conv_\" + block + \"_2\", X)\n",
        "  X = conv_set(F3, (1,1), (1,1), name+\"_res_conv_\" + block + \"_3\", X)\n",
        "\n",
        "  #X_shortcut = conv_set(F3, (1,1), (2,2), name+\"_res_conv_shortcut_\" + block, X)\n",
        "  #X = layers.add([X, X_shortcut])\n",
        "  return X\n",
        "\n",
        "def Bus(bus, name, width, X):\n",
        "  B = layers.Dense(width, activity_regularizer=regularizers.l2(L2Reg), name=\"bus_input_dense\"+name)(layers.Flatten()(X))\n",
        "  B = layers.concatenate([bus, B], name=\"bus_merge_\"+name)\n",
        "  B = layers.Dense(width, activity_regularizer=regularizers.l2(L2Reg), name=\"bus_dense_\"+name)(B)\n",
        "  return B\n",
        "\n",
        "\n",
        "# X is batch, frames, bin, layers\n",
        "def Harmonics_fn(X, bins_per_octave):\n",
        "  Trimmed_X = K.slice(X, [0,0,0,0], [-1,-1,X.shape[2]-bins_per_octave,-1])\n",
        "  Shift_X =  K.slice(X, [0,0,bins_per_octave,0], [-1,-1,-1,-1])\n",
        "  return K.concatenate([Trimmed_X, Shift_X])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rFvcqvI9uqo7",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# Real model (eventually)\n",
        "ALPHA = 0.05\n",
        "L2Reg = 0.0000 # bumping this up to 0.000005 didn't seem very good\n",
        "\n",
        "inputs = layers.Input(shape=(WINDOW_SIZE,FFT_BINS,3)) # Full window\n",
        "\n",
        "NARROW_VIEW = 15\n",
        "BUS_WIDTH = 100\n",
        "\n",
        "# WARNING - if I put a constant in the lambda function, it causes an error when loading the model\n",
        "def sub_samples(samples, n, window_size):\n",
        "    half_cut = (window_size - n) // 2\n",
        "    return samples[:,half_cut:-half_cut,:,:]\n",
        "\n",
        "# Add x and y component layers --- TODO if this doesn't work wll\n",
        "#M = Magnitude(inputs)\n",
        "#inputs_M = layers.concatenate([inputs, M], axis=-1)\n",
        "\n",
        "# process inputs into subsets of interest\n",
        "input_slice = layers.Lambda(sub_samples, arguments = {'n':1, 'window_size':WINDOW_SIZE}, name=\"targetslice\")(inputs)\n",
        "narrow_view = layers.Lambda(sub_samples, arguments = {'n':NARROW_VIEW, 'window_size':WINDOW_SIZE}, name=\"narrow_view\")(inputs)\n",
        "\n",
        "# broad view\n",
        "X = conv_set(64,(4,4), (1,1), \"bconv0\", inputs)\n",
        "X = conv_set(32,(3,6), (1,2), \"bconv1\", X)\n",
        "X = conv_set(32,(3,6), (1,2), \"bconv2\", X)\n",
        "X = pool_set((2,4), (1,2), \"bpool1\", X)\n",
        "side = conv_set(16, (4,10), (2,3), \"side_prep1\", X)\n",
        "bus = layers.Dense(BUS_WIDTH, activity_regularizer=regularizers.l2(L2Reg), name=\"bus_initial_dense\")(layers.Flatten()(side))  # Start of side path\n",
        "X = res_conv_block(3, filters=[32, 32, 128], name=\"b_res\", block=\"A\", X=X )\n",
        "X = pool_set((4,4), (2,2), \"bpool2\", X)\n",
        "X = conv_set(32, (4,6), (1,1), \"bconv3\", X)\n",
        "X = conv_set(64, (4,6), (1,1), \"bconv4\", X)\n",
        "side = conv_set(16, (2,3), (1,1), \"side_prep2\", X)\n",
        "bus = Bus(bus, \"b3\", BUS_WIDTH, side)\n",
        "X = pool_set((4,4), (2,2), \"bpool3\", X)\n",
        "X = conv_set(16, (2,2), (1,1), \"bconv5\", X)\n",
        "X = layers.BatchNormalization(name=\"b_norm\")(X)\n",
        "flat_b = layers.Flatten(name=\"flat_b\")(X)\n",
        "\n",
        "# harmonics view\n",
        "H = layers.Lambda(Harmonics_fn, arguments={'bins_per_octave':BINS_PER_OCTAVE}, name=\"harmonics1\")(inputs)\n",
        "H = conv_set(64,(5,5), (1,1), \"hconv0\", H)\n",
        "H = layers.Lambda(Harmonics_fn, arguments={'bins_per_octave':BINS_PER_OCTAVE}, name=\"harmonics1\")(inputs)\n",
        "H = conv_set(64,(5,5), (1,1), \"hconv1\", H)\n",
        "H = conv_set(128,(5,5), (2,3), \"hconv2\", H)\n",
        "H = pool_set((4,4), (1,2), \"hpool1\", H)\n",
        "H = conv_set(64,(5,5), (1,2), \"hconv3\", H)\n",
        "H = conv_set(32,(5,5), (1,2), \"hconv4\", H)\n",
        "H = pool_set((4,4), (1,2), \"hpool2\", H)\n",
        "flat_h = layers.Flatten(name=\"flat_h\")(H)\n",
        "\n",
        "\n",
        "# narrow view - leaving this out for now ------------------------ TODO try it again?\n",
        "X = conv_set(32, (3,6), (1,2), \"conv0\", narrow_view)\n",
        "X = conv_set(64, (3,6), (1,1), \"conv1\", X)\n",
        "X = res_conv_block(3, filters=[32, 32, 128], name=\"nr_res\", block=\"A\", X=X )\n",
        "#X = conv_set(64, (3,7), (1,2), \"conv2\", narrow_view)\n",
        "#side = conv_set(16, (4,10), (2,3), \"side_prep_n1\", X)\n",
        "#bus = Bus(bus, \"n1\", BUS_WIDTH, side)\n",
        "X = pool_set((2,4), (1,2), \"pool1\", X)\n",
        "#X = res_conv_block(3, filters=[32, 32, 128], name=\"nr_res\", block=\"B\", X=X )\n",
        "X = conv_set(128, (3,5), (1,1), \"conv3\", X)\n",
        "#X = res_conv_block(3, filters=[32, 32, 128], name=\"nr_res\", block=\"C\", X=X )\n",
        "X = conv_set(128, (3,5), (1,2), \"conv4\", X)\n",
        "X = conv_set(16, (3,5), (1,1), \"conv5\", X)\n",
        "X = pool_set((2,3), (1,2), \"pool2\", X)\n",
        "X = layers.BatchNormalization(name=\"n_norm\")(X)\n",
        "flat_n = layers.Flatten(name=\"flat_n\")(X)\n",
        "\n",
        "flat = layers.concatenate([flat_b, flat_h], name=\"merge_modes\")   # , bus ------------ TODO put this back\n",
        "\n",
        "flat_in = layers.Flatten(name=\"flatten\")(input_slice)\n",
        "\n",
        "flat_drop = layers.Dropout(rate=0.2)(flat)  # Add this later\n",
        "dense0 = layers.Dense(500, activity_regularizer=regularizers.l2(L2Reg))(flat_drop)\n",
        "d0a = layers.LeakyReLU(alpha=ALPHA)(dense0)\n",
        "dense1 = layers.Dense(300, activity_regularizer=regularizers.l2(L2Reg))(d0a)\n",
        "d1a = keras.layers.LeakyReLU(alpha=ALPHA)(dense1)\n",
        "dense2 = layers.Dense(200, )(d1a)\n",
        "d2a = keras.layers.LeakyReLU(alpha=ALPHA)(dense2)\n",
        "\n",
        "outputs = layers.Reshape((FFT_BINS,3)) (layers.Dense(3 * FFT_BINS, activation='linear')(d2a))\n",
        "#output_bias = layers.Reshape((FFT_BINS,3)) (layers.Dense(3 * FFT_BINS, activation='linear')(d2a))\n",
        "#output_scale = layers.Reshape((FFT_BINS,3)) (layers.Dense(3 * FFT_BINS, activation='linear')(d2a))\n",
        "\n",
        "#outputs = layers.Multiply()([input_slice,output_scale])   #layers.Add()([layers.Multiply()([input_slice,output_scale]),output_bias])\n",
        "\n",
        "\n",
        "model = keras.models.Model(inputs=[inputs], outputs=outputs)\n",
        "model.compile(optimizer='Adam', loss='mse')\n",
        "now = time.strftime('%Y-%m-%d_%H-%M')\n",
        "model.name=\"CQT_Model-B\"+str(FFT_BINS)+\"-W\"+str(WINDOW_SIZE)+\"-DT\"+now\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ErQAka1B6A1",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=True, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zG4Ie6wWVqiQ",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "48de527d-b2af-4a29-933a-487a02317f82"
      },
      "source": [
        "# fit_generator\n",
        "# Go back and add log tracking using model name for folder\n",
        "stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "save_best = keras.callbacks.ModelCheckpoint(drive_data + \"Last_best_\"+model.name+\".h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "# Max queue size is to fix \"UserWarning: The input 6833 could not be retrieved. It could be because a worker has died.\"\n",
        "#  10 didn't work once for 500K samples, 1025 bins but tried 5 and that seemed to\n",
        "#  Trying a fix by copying to local directory - may boost speed as well?\n",
        "print(model.name)\n",
        "hist = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=2, callbacks = [stopper, save_best]) #, max_queue_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CQT_Model-B480-W55-DT2020-02-01_21-20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/2\n",
            " 106/4452 [..............................] - ETA: 35:47 - loss: 0.3113"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BPctpbJIg6rC",
        "colab": {}
      },
      "source": [
        "model.save(drive_data + model.name + \".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EqG_dSiTkTwj",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "history = hist\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim((0, 2 * history.history['loss'][0])) # because sometimes there are stupid spikes in error\n",
        "plt.show()\n",
        "\n",
        "#plt.savefig('test.png')\n",
        "print(\"Validation loss mean 5+ epochs {0:.4}\".format(np.mean(history.history['val_loss'][5:])))\n",
        "print(\"Lowest validation loss {0:.4}\".format(np.min(history.history['val_loss'][5:])))\n",
        "print(\"Frames \", frames.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-lCNToBxkTwR",
        "colab": {}
      },
      "source": [
        "# some test data to hack around with\n",
        "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\p232_010.wav\"\n",
        "wav, rate = librosa.core.load(test_file)\n",
        "fft = get_ft(wav)\n",
        "#print(fft.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c8DZfaSgkTwn",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# Full round trip test\n",
        "file = \"p232_001.wav\"\n",
        "\n",
        "verify_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\\" + file\n",
        "clean_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\\" + file\n",
        "\n",
        "\n",
        "# Sample output is (samples, bins) all converted to magnitude\n",
        "def get_samples(file):\n",
        "    wav, rate = librosa.core.load(file)\n",
        "    samples = abs(get_ft(wav).T) # organized as bins, frames so we need to transpose them to frames, bins\n",
        "    return samples\n",
        "\n",
        "# Only need this for testing at this point?  Could still make it a 'top' type shared function\n",
        "def clip_frames(file):\n",
        "    samples = get_samples(file)\n",
        "    print(samples.shape)\n",
        "    frames = np.empty((samples.shape[0], WINDOW_SIZE, FFT_BINS, 1))\n",
        "    half_win = WINDOW_SIZE//2\n",
        "    for i in range(half_win, samples.shape[0]-half_win):\n",
        "        frames[i,:,:,0] = samples[i-half_win:i+half_win+1,:]\n",
        "    return frames\n",
        "\n",
        "\n",
        "def clean_clip(model, n_file):\n",
        "    verify_frames = clip_frames(n_file)\n",
        "    output_targets = model.predict([verify_frames])\n",
        "    wav, rate = librosa.core.load(n_file)\n",
        "    n_fft = get_ft(wav)\n",
        "    fft = rebuild_fft(output_targets, n_fft)\n",
        "    return fft, inv_ft(fft)\n",
        "\n",
        "\n",
        "p_fft, p_wav = clean_clip(model, verify_file)\n",
        "    \n",
        "wav, rate = librosa.core.load(clean_file)\n",
        "c_fft = get_ft(wav)\n",
        "\n",
        "\n",
        "def display_fft(ft):\n",
        "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(ft), ref=np.max), y_axis='cqt_hz', x_axis='time')\n",
        "\n",
        "print(\"Cleaned clip\")\n",
        "\n",
        "err_fft = c_fft - p_fft\n",
        "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
        "\n",
        "display_fft(p_fft)\n",
        "Audio(p_wav,rate=22050)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sqHS_31nkTwp",
        "colab": {}
      },
      "source": [
        "def draw(wav):\n",
        "    fft = get_ft(wav)\n",
        "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='cqt_hz', x_axis='time')\n",
        "    return fft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3xhtGoYOkTwr",
        "colab": {}
      },
      "source": [
        "wav, rate = librosa.core.load(verify_file)\n",
        "n_fft = draw(wav)\n",
        "\n",
        "err_fft = c_fft - n_fft\n",
        "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
        "\n",
        "print(\"Noisy file\")\n",
        "Audio(wav, rate=rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oeyY6RDTkTwu",
        "colab": {}
      },
      "source": [
        "wav, rate = librosa.core.load(clean_file)\n",
        "c_fft = draw(wav)\n",
        "\n",
        "print(\"Clean sample\")\n",
        "Audio(wav, rate=rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zO4WwsB9kTww",
        "colab": {}
      },
      "source": [
        "cut_fft = n_fft-p_fft\n",
        "display_fft(cut_fft)\n",
        "\n",
        "print(\"Removed audio\")\n",
        "print(\"Average cut value = \", np.mean(abs(cut_fft)))\n",
        "\n",
        "cut_wav = inv_ft(cut_fft)\n",
        "Audio(cut_wav,rate=22050)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_tC3WpzokTwy",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k7wCtwF4kTw0",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "#%%capture cap\n",
        "print(model.summary())\n",
        "#with open('output.txt', 'w') as f:\n",
        "#    f.write(cap.stdout)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0b_mGnNZkTw3",
        "colab": {}
      },
      "source": [
        "fresh_wav, rate = librosa.core.load(\"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\p232_019.wav\")\n",
        "Audio(fresh_wav, rate=rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "peLEO0VZkTw6"
      },
      "source": [
        "Test & reference stuff "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ibbfUgj5kTwf",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# Real model (eventually)\n",
        "ALPHA = 0.05\n",
        "L2Reg = 0.0000 # bumping this up to 0.000005 didn't seem very good\n",
        "\n",
        "inputs = layers.Input(shape=(WINDOW_SIZE,FFT_BINS,1)) # Full window\n",
        "\n",
        "NARROW_VIEW = 15\n",
        "BUS_WIDTH = 100\n",
        "\n",
        "# WARNING - if I put a constant in the lambda function, it causes an error when loading the model\n",
        "def sub_samples(samples, n, window_size):\n",
        "    half_cut = (window_size - n) // 2\n",
        "    return samples[:,half_cut:-half_cut,:,:]\n",
        "    \n",
        "# process inputs into subsets of interest\n",
        "input_slice = layers.Lambda(sub_samples, arguments = {'n':1, 'window_size':WINDOW_SIZE}, name=\"targetslice\")(inputs)\n",
        "narrow_view = layers.Lambda(sub_samples, arguments = {'n':NARROW_VIEW, 'window_size':WINDOW_SIZE}, name=\"narrow_view\")(inputs)\n",
        "\n",
        "# zoomed out view\n",
        "X = layers.AveragePooling2D(pool_size=(3,3), strides=(2,2), name=\"broad_pool1\")(inputs)\n",
        "X = conv_set(32,(3,6), (1,2), \"bconv1\", X)\n",
        "X = res_conv_block(5, filters=[32, 32, 128], name=\"br_res\", block=\"A\", X=X )\n",
        "#X = res_conv_block(5, filters=[32, 32, 128], name=\"br_res\", block=\"B\", X=X )\n",
        "X = conv_set(64, (3,6), (1,2), \"bconv2\", X)\n",
        "side = conv_set(16, (4,10), (1,3), \"side_prep1\", X)\n",
        "bus = layers.Dense(BUS_WIDTH, activity_regularizer=regularizers.l2(L2Reg), name=\"bus_initial_dense\")(layers.Flatten()(side))  # Start of side path\n",
        "#X = res_conv_block(5, filters=[32, 32, 128], name=\"br_res\", block=\"C\", X=X )\n",
        "X = conv_set(128, (4,6), (1,2), \"bconv3\", X)\n",
        "X = conv_set(32, (4,6), (1,2), \"bconv4\", X)\n",
        "side = conv_set(16, (2,3), (1,1), \"side_prep2\", X)\n",
        "bus = Bus(bus, \"b3\", BUS_WIDTH, side)\n",
        "X = pool_set((2,4), (1,2), \"bpool2\", X)\n",
        "X = layers.BatchNormalization(name=\"b_norm\")(X)\n",
        "flat_b = layers.Flatten(name=\"flat_b\")(X)\n",
        "\n",
        "# narrow view\n",
        "X = conv_set(32, (3,7), (1,2), \"conv0\", narrow_view)\n",
        "X = conv_set(64, (3,7), (1,2), \"conv1\", narrow_view)\n",
        "X = res_conv_block(3, filters=[32, 32, 128], name=\"nr_res\", block=\"A\", X=X )\n",
        "X = conv_set(64, (3,7), (1,2), \"conv2\", narrow_view)\n",
        "X = pool_set((2,3), (1,2), \"pool1\", X)\n",
        "#X = res_conv_block(3, filters=[32, 32, 128], name=\"nr_res\", block=\"B\", X=X )\n",
        "X = conv_set(128, (3,7), (1,2), \"conv3\", X)\n",
        "X = res_conv_block(3, filters=[32, 32, 128], name=\"nr_res\", block=\"C\", X=X )\n",
        "X = conv_set(128, (3,7), (1,2), \"conv4\", X)\n",
        "X = conv_set(32, (3,7), (1,2), \"conv5\", X)\n",
        "X = pool_set((2,3), (1,2), \"pool2\", X)\n",
        "X = layers.BatchNormalization(name=\"n_norm\")(X)\n",
        "flat_n = layers.Flatten(name=\"flat_n\")(X)\n",
        "\n",
        "flat = layers.concatenate([flat_b, flat_n, bus], name=\"merge_modes\")\n",
        "\n",
        "flat_in = layers.Flatten(name=\"flatten\")(input_slice)\n",
        "\n",
        "flat_drop = layers.Dropout(rate=0.2)(flat)  # Add this later\n",
        "\n",
        "dense0 = layers.Dense(700, activity_regularizer=regularizers.l2(L2Reg))(flat_drop)\n",
        "d0a = layers.LeakyReLU(alpha=ALPHA)(dense0)\n",
        "merge1 = layers.concatenate([d0a, flat_in], name=\"merge_input\")\n",
        "\n",
        "dense1 = layers.Dense(500, activity_regularizer=regularizers.l2(L2Reg))(merge1)\n",
        "d1a = keras.layers.LeakyReLU(alpha=ALPHA)(dense1)\n",
        "dense2 = layers.Dense(300, )(d1a)\n",
        "d2a = keras.layers.LeakyReLU(alpha=ALPHA)(dense2)\n",
        "merged = layers.concatenate([d2a, flat_in])\n",
        "outputs = layers.Dense(FFT_BINS, activation='linear')(merged)\n",
        "\n",
        "model = keras.models.Model(inputs=[inputs], outputs=outputs)\n",
        "\n",
        "model.compile(optimizer='Adam', loss='mse')\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BPX3_ZiMkTw7",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "ft = clip_frames(test_file)\n",
        "tt = clip_targets(test_file)\n",
        "\n",
        "print(ft.shape)\n",
        "print(tt.shape)\n",
        "\n",
        "#Frame / target check  -  don't use first row because it might be zeroed out\n",
        "r = 10\n",
        "print(tt[0,r])\n",
        "print(ft[0,r,TARGET_COL:TARGET_COL+1,0])\n",
        "\n",
        "# Round trip test\n",
        "new_fft = rebuild_fft(tt, fft)\n",
        "print(new_fft.shape)\n",
        "new_wav = inv_ft(new_fft)\n",
        "\n",
        "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='log', x_axis='time')\n",
        "\n",
        "Audio(new_wav,rate=22050)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k67NuIJQkTw-",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "    \n",
        "def show_fft(wav):\n",
        "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(librosa.stft(wav)), ref=np.max), y_axis='log', x_axis='time')\n",
        "\n",
        "def display_fft(ft):\n",
        "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='log', x_axis='time')\n",
        "\n",
        "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='log', x_axis='time')\n",
        "\n",
        "print(new_fft.shape)\n",
        "\n",
        "#show_fft(wav)\n",
        "#show_fft(new_wav)\n",
        "#Audio(wav, rate=22050)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M4HRcM0rkTxA",
        "colab": {}
      },
      "source": [
        "# Test stuff for hacking around    \n",
        "    \n",
        "a = np.array([[1+2j, 3+4j, 1.5+2.5j],[5+6j,7+8j, 5.5+6.5j]])\n",
        "print(a)\n",
        "a1 = a[0]\n",
        "print(a1)\n",
        "ar = a1.real\n",
        "ai = a1.imag\n",
        "\n",
        "st = np.zeros((6))\n",
        "st[0:3] = ar\n",
        "st[3:6] = ai\n",
        "print(ar.shape, ai.shape, st.shape)\n",
        "print(ar, ai)\n",
        "print(st)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lofx2hiEkTxC",
        "colab": {}
      },
      "source": [
        "# ''do nothing' model that should be able to guess outputs from outputs\n",
        "\n",
        "inputs = layers.Input(shape=(FFT_BINS*2,))\n",
        "dense1 = layers.Dense(2000, activation='relu')(inputs)\n",
        "dense2 = layers.Dense(2000, activation='relu')(dense1)\n",
        "#flat = layers.Flatten()(dense)\n",
        "#flat_in = layers.Flatten()(inputs)\n",
        "#merged = layers.concatenate([flat, flat_in])\n",
        "merged = layers.concatenate([dense2, inputs])\n",
        "linear = layers.Dense(2000, activation='linear')(merged)\n",
        "outputs = layers.Dense(2*FFT_BINS, activation='linear')(linear)\n",
        "\n",
        "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer='Adam', loss='mse')\n",
        "\n",
        "model.fit(targets, targets, epochs=1, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}