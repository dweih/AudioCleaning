{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugJNGnNlkTwI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import cmath\n",
    "\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "from keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPWfsAnkkgxD"
   },
   "outputs": [],
   "source": [
    "# If on google colab, run this\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "os.chdir('drive/My Drive/Projects/Audio Separation/Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X4ZOOJsSkTwM"
   },
   "source": [
    "Rewriten to use a single stream of data and on the fly creation of batch data\n",
    "\n",
    "TODO\n",
    "* Change name from frames to samples everywhere\n",
    "\n",
    "* Go back to cqt??\n",
    "\n",
    "* Add drop out\n",
    "\n",
    "* Use callbacks for LR reduction and to save best models with error info\n",
    "\n",
    "* Automatic logging of graphs, errors, models etc. for comparison\n",
    "* Add graph of model\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file='model.png')\n",
    "* Create log output function, then capture to text file (also export graphs?)\n",
    "\n",
    "* Look for sources of noise that are close to what I want?  Or generate some clips?\n",
    "\n",
    "* Debugging tools for comparing, listening to, and viewing clips\n",
    "* Add audio quality comparisons between clean clips and cleaned clips for evaluation\n",
    "\n",
    "* Add history error plotting to compare different learning models, topologies, etc.\n",
    "\n",
    "* Look into streaming frames to & from file and having way more samples\n",
    "\n",
    "* Why does https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785 only use real component?\n",
    "* Evaluate different representations of complex numbers in terms of learnability\n",
    "\n",
    "* Consider generating custom data for goal - male speakers, low voice, specific sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0NWhq04kTwN"
   },
   "outputs": [],
   "source": [
    "# Constants and settings\n",
    "WINDOW_SIZE = 25  # Has to be odd\n",
    "TARGET_COL = WINDOW_SIZE//2\n",
    "\n",
    "DTYPE = 'float32'\n",
    "\n",
    "# cqt related\n",
    "FFT_BINS = 513 # function of items below\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "# stft values\n",
    "N_FFT = 1024 # 512 recommended for speech, music typically 2048\n",
    "\n",
    "# cqt values\n",
    "BINS_PER_OCTAVE = 12 * 10\n",
    "FMIN = librosa.note_to_hz('C1')\n",
    "OCTAVES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUhAB8HrkTwP"
   },
   "outputs": [],
   "source": [
    "# Idea here is that we operate on magnitude, and will just use phase from the original noisy sample\n",
    "\n",
    "def combine_target(t):\n",
    "    return (t[0:t.shape[0]//2] + 1j * t[t.shape[0]//2:]).reshape(1,(t.shape[0]//2))\n",
    "\n",
    "def rebuild_fft(output, original_fft):\n",
    "    vphase = np.vectorize(cmath.phase)\n",
    "    o_phase = vphase(original_fft)\n",
    "    mag = output.T\n",
    "    vrect = np.vectorize(cmath.rect)\n",
    "    return vrect(mag, o_phase)\n",
    "    \n",
    "# build up as (bins, samples) then transpose to model view of (samples, bins)\n",
    "def targets_to_fft(targets):\n",
    "    fft = np.empty((targets.shape[0],targets.shape[1]//2), dtype='complex64')\n",
    "    for i in range(0, targets.shape[0]):\n",
    "        fft[i] = combine_target(targets[i])\n",
    "    return fft.T   # transpose\n",
    "\n",
    "def get_ft(wav):\n",
    "    #c = librosa.cqt(wav, hop_length=HOP_LENGTH, fmin=FMIN, n_bins=OCTAVES*BINS_PER_OCTAVE, bins_per_octave=BINS_PER_OCTAVE)\n",
    "    c = librosa.stft(wav, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "    return c\n",
    "\n",
    "def inv_ft(ft):\n",
    "    #return librosa.icqt(ft, hop_length=HOP_LENGTH, bins_per_octave=BINS_PER_OCTAVE)\n",
    "    return librosa.istft(ft, hop_length=HOP_LENGTH)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mgM7ZVjlStg"
   },
   "outputs": [],
   "source": [
    "# For local data\n",
    "samples=100000\n",
    "frames = np.memmap(\"f://audiodata//fsamples-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 1))\n",
    "targets = np.memmap(\"f://audiodata//ftargets-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mgM7ZVjlStg"
   },
   "outputs": [],
   "source": [
    "# For collab data\n",
    "samples = 100000\n",
    "frames = np.memmap(\"fsamples-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 1))\n",
    "targets = np.memmap(\"ftargets-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ur6yJmzVkTwc"
   },
   "outputs": [],
   "source": [
    "# Code to generate input, target, and verification data\n",
    "# From https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, input_array, target_array, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.input_array = input_array\n",
    "        self.target_array = target_array\n",
    "        self.dim = (WINDOW_SIZE,FFT_BINS) # Input data shape\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs  # the set of allowed IDs to use as addresses for frames and target samples\n",
    "        self.n_channels = 1\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, FFT_BINS), dtype=DTYPE)\n",
    "\n",
    "        # Generate data\n",
    "        half_win = WINDOW_SIZE // 2\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample & target\n",
    "            X[i,] = self.input_array[ID-half_win:ID+half_win+1,:,:]\n",
    "            y[i] = self.target_array[ID,:]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the generator\n",
    "validation_split = 0.05\n",
    "\n",
    "# Available IDs\n",
    "all_IDs = np.arange(WINDOW_SIZE//2, frames.shape[0]-WINDOW_SIZE//2)\n",
    "np.random.shuffle(all_IDs)\n",
    "\n",
    "validation_cut = int(np.floor(len(all_IDs) * (1-validation_split)))\n",
    "validation_IDs = all_IDs[validation_cut:]\n",
    "train_IDs = all_IDs[0:validation_cut-1]\n",
    "\n",
    "training_generator = DataGenerator(train_IDs, frames, targets)\n",
    "validation_generator = DataGenerator(validation_IDs, frames, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 25, 513, 1)\n",
      "(32, 513)\n"
     ]
    }
   ],
   "source": [
    "X, y = training_generator.__getitem__(0)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibbfUgj5kTwf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 25, 513, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 21, 1, 64)    164224      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 21, 1, 64)    0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 17, 1, 32)    10272       leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 17, 1, 32)    0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flat_h (Flatten)                (None, 544)          0           leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 500)          272500      flat_h[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "targetslice (Lambda)            (None, 1, 513, 1)    0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 500)          0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 513)          0           targetslice[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 1013)         0           leaky_re_lu_23[0][0]             \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 300)          304200      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 300)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 813)          0           leaky_re_lu_24[0][0]             \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 513)          417582      concatenate_11[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,168,778\n",
      "Trainable params: 1,168,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Real model (eventually)\n",
    "ALPHA = 0.05\n",
    "L2Reg = 0.00000 # bumping this up to 0.000005 didn't seem very good\n",
    "\n",
    "inputs = layers.Input(shape=(WINDOW_SIZE,FFT_BINS,1)) # Full window\n",
    "\n",
    "def sub_samples(samples, n):\n",
    "    half_cut = (WINDOW_SIZE - n) // 2\n",
    "    print (half_cut)\n",
    "    return samples[:,half_cut:-half_cut,:,:]\n",
    "    \n",
    "# process inputs into subsets of interest\n",
    "input_slice = layers.Lambda(sub_samples, arguments = {'n':1}, name=\"targetslice\")(inputs)\n",
    "\n",
    "# Horizontal first - across bins then samples\n",
    "conv1 = layers.Conv2D(64, kernel_size=(5,FFT_BINS), activity_regularizer=regularizers.l2(L2Reg), name=\"conv1\")(inputs)\n",
    "c1a = layers.LeakyReLU(alpha=ALPHA)(conv1)\n",
    "conv2 = layers.Conv2D(32, kernel_size=(5,1), activity_regularizer=regularizers.l2(L2Reg), name=\"conv2\")(c1a)\n",
    "c2a = layers.LeakyReLU(alpha=ALPHA)(conv2)\n",
    "flat_h = layers.Flatten(name=\"flat_h\")(c2a)\n",
    "\n",
    "# Vertical features - across samples then bins\n",
    "#conv3 = layers.Conv2D(64, kernel_size=(WINDOW_SIZE,100), activity_regularizer=regularizers.l2(L2Reg), name=\"conv3\")(inputs) \n",
    "#c3a = layers.LeakyReLU(alpha=ALPHA)(conv3)\n",
    "#flat_v = layers.Flatten(name=\"flat_v\")(c3a)\n",
    "\n",
    "flat = flat_h #layers.concatenate([flat_h, flat_v])\n",
    "\n",
    "flat_in = layers.Flatten()(input_slice)\n",
    "\n",
    "dense0 = layers.Dense(500, activity_regularizer=regularizers.l2(L2Reg))(flat)\n",
    "d0a = layers.LeakyReLU(alpha=ALPHA)(dense0)\n",
    "merge1 = layers.concatenate([d0a, flat_in])\n",
    "\n",
    "dense1 = layers.Dense(300, activity_regularizer=regularizers.l2(L2Reg))(merge1)\n",
    "d1a = keras.layers.LeakyReLU(alpha=ALPHA)(dense1)\n",
    "#dense2 = layers.Dense(500, )(dense1)\n",
    "#d2a = keras.layers.LeakyReLU(alpha=ALPHA)(dense2)\n",
    "merged = layers.concatenate([d1a, flat_in])\n",
    "outputs = layers.Dense(FFT_BINS, activation='linear')(merged)\n",
    "\n",
    "model = keras.models.Model(inputs=[inputs], outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      " 261/2968 [=>............................] - ETA: 25:46 - loss: 0.0316"
     ]
    }
   ],
   "source": [
    "# fit_generator that uses \n",
    "stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=15, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "save_best = keras.callbacks.ModelCheckpoint(\"Best_model.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "hist = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=10, callbacks = [stopper, save_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqG_dSiTkTwj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = hist\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.ylim((0, 2 * history.history['loss'][0])) # because sometimes there are stupid spikes in error\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('test.png')\n",
    "print(\"Validation loss mean 5+ epochs {0:.4}\".format(np.mean(history.history['val_loss'][5:])))\n",
    "print(\"Lowest validation loss {0:.4}\".format(np.min(history.history['val_loss'][5:])))\n",
    "print(\"Frames \", frames.shape[0])\n",
    "\n",
    "#Add verification means for 1-10, 11-20, 21-30?  Or slope for different ranges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tuZ62OokTwl"
   },
   "outputs": [],
   "source": [
    "# Not required because of 'restore best weights'\n",
    "#model = keras.models.load_model(\"Best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lCNToBxkTwR"
   },
   "outputs": [],
   "source": [
    "# some test data to hack around with\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\p232_010.wav\"\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "fft = get_ft(wav)\n",
    "#print(fft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8DZfaSgkTwn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Full round trip test\n",
    "file = \"p232_001.wav\"\n",
    "\n",
    "verify_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\\" + file\n",
    "clean_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\\" + file\n",
    "\n",
    "def clean_clip(model, n_file):\n",
    "    verify_frames = clip_frames(n_file)\n",
    "    output_targets = model.predict([verify_frames, verify_frames[:,:,TARGET_COL:TARGET_COL+1,:]])\n",
    "    wav, rate = librosa.core.load(n_file)\n",
    "    n_fft = get_ft(wav)\n",
    "    fft = rebuild_fft(output_targets, n_fft)\n",
    "    return fft, inv_ft(fft)\n",
    "\n",
    "p_fft, p_wav = clean_clip(model, verify_file)\n",
    "    \n",
    "wav, rate = librosa.core.load(clean_file)\n",
    "c_fft = get_ft(wav)\n",
    "\n",
    "\n",
    "def display_fft(ft):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "print(\"Cleaned clip\")\n",
    "\n",
    "err_fft = c_fft - p_fft\n",
    "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
    "\n",
    "display_fft(p_fft)\n",
    "Audio(p_wav,rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqHS_31nkTwp"
   },
   "outputs": [],
   "source": [
    "def draw(wav):\n",
    "    fft = librosa.stft(wav, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "    return fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xhtGoYOkTwr"
   },
   "outputs": [],
   "source": [
    "wav, rate = librosa.core.load(verify_file)\n",
    "n_fft = draw(wav)\n",
    "\n",
    "print(\"Noisy file\")\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeyY6RDTkTwu"
   },
   "outputs": [],
   "source": [
    "wav, rate = librosa.core.load(clean_file)\n",
    "c_fft = draw(wav)\n",
    "\n",
    "print(\"Clean sample\")\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zO4WwsB9kTww"
   },
   "outputs": [],
   "source": [
    "cut_fft = n_fft-p_fft\n",
    "display_fft(cut_fft)\n",
    "\n",
    "print(\"Removed audio\")\n",
    "print(\"Average cut value = \", np.mean(abs(cut_fft)))\n",
    "\n",
    "cut_wav = inv_ft(cut_fft)\n",
    "Audio(cut_wav,rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tC3WpzokTwy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7wCtwF4kTw0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%capture cap\n",
    "print(model.summary())\n",
    "#with open('output.txt', 'w') as f:\n",
    "#    f.write(cap.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0b_mGnNZkTw3"
   },
   "outputs": [],
   "source": [
    "fresh_wav, rate = librosa.core.load(\"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\p232_019.wav\")\n",
    "Audio(fresh_wav, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peLEO0VZkTw6"
   },
   "source": [
    "Test & reference stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPX3_ZiMkTw7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ft = clip_frames(test_file)\n",
    "tt = clip_targets(test_file)\n",
    "\n",
    "print(ft.shape)\n",
    "print(tt.shape)\n",
    "\n",
    "#Frame / target check  -  don't use first row because it might be zeroed out\n",
    "r = 10\n",
    "print(tt[0,r])\n",
    "print(ft[0,r,TARGET_COL:TARGET_COL+1,0])\n",
    "\n",
    "# Round trip test\n",
    "new_fft = rebuild_fft(tt, fft)\n",
    "print(new_fft.shape)\n",
    "new_wav = inv_ft(new_fft)\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "Audio(new_wav,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k67NuIJQkTw-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "def show_fft(wav):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(librosa.stft(wav)), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "def display_fft(ft):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "print(new_fft.shape)\n",
    "\n",
    "#show_fft(wav)\n",
    "#show_fft(new_wav)\n",
    "#Audio(wav, rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4HRcM0rkTxA"
   },
   "outputs": [],
   "source": [
    "# Test stuff for hacking around    \n",
    "    \n",
    "a = np.array([[1+2j, 3+4j, 1.5+2.5j],[5+6j,7+8j, 5.5+6.5j]])\n",
    "print(a)\n",
    "a1 = a[0]\n",
    "print(a1)\n",
    "ar = a1.real\n",
    "ai = a1.imag\n",
    "\n",
    "st = np.zeros((6))\n",
    "st[0:3] = ar\n",
    "st[3:6] = ai\n",
    "print(ar.shape, ai.shape, st.shape)\n",
    "print(ar, ai)\n",
    "print(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lofx2hiEkTxC"
   },
   "outputs": [],
   "source": [
    "# ''do nothing' model that should be able to guess outputs from outputs\n",
    "\n",
    "inputs = layers.Input(shape=(FFT_BINS*2,))\n",
    "dense1 = layers.Dense(2000, activation='relu')(inputs)\n",
    "dense2 = layers.Dense(2000, activation='relu')(dense1)\n",
    "#flat = layers.Flatten()(dense)\n",
    "#flat_in = layers.Flatten()(inputs)\n",
    "#merged = layers.concatenate([flat, flat_in])\n",
    "merged = layers.concatenate([dense2, inputs])\n",
    "linear = layers.Dense(2000, activation='linear')(merged)\n",
    "outputs = layers.Dense(2*FFT_BINS, activation='linear')(linear)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "model.fit(targets, targets, epochs=1, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NN Audio Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
