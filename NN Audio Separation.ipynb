{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NN Audio Test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ugJNGnNlkTwI",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "from IPython.display import Audio, display\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import time\n",
        "import cmath\n",
        "\n",
        "import keras\n",
        "import keras.layers as layers\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "from keras import regularizers\n",
        "from keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cPWfsAnkkgxD",
        "colab": {}
      },
      "source": [
        "# If on google colab, run this\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir('drive/My Drive/Projects/Audio Separation/Data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X4ZOOJsSkTwM"
      },
      "source": [
        "Rewriten to use a single stream of data and on the fly creation of batch data\n",
        "\n",
        "TODO\n",
        "* Add saving best models\n",
        "\n",
        "* Change name from frames to samples everywhere\n",
        "\n",
        "* Go back to cqt??\n",
        "\n",
        "* Add drop out\n",
        "\n",
        "* Use callbacks for LR reduction and to save best models with error info\n",
        "\n",
        "* Automatic logging of graphs, errors, models etc. for comparison\n",
        "* Add graph of model\n",
        "    from keras.utils import plot_model\n",
        "    plot_model(model, to_file='model.png')\n",
        "* Create log output function, then capture to text file (also export graphs?)\n",
        "\n",
        "* Look for sources of noise that are close to what I want?  Or generate some clips?\n",
        "\n",
        "* Debugging tools for comparing, listening to, and viewing clips\n",
        "* Add audio quality comparisons between clean clips and cleaned clips for evaluation\n",
        "\n",
        "* Add history error plotting to compare different learning models, topologies, etc.\n",
        "\n",
        "* Look into streaming frames to & from file and having way more samples\n",
        "\n",
        "* Why does https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785 only use real component?\n",
        "* Evaluate different representations of complex numbers in terms of learnability\n",
        "\n",
        "* Consider generating custom data for goal - male speakers, low voice, specific sounds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a0NWhq04kTwN",
        "colab": {}
      },
      "source": [
        "# Constants and settings\n",
        "WINDOW_SIZE = 55  # Has to be odd\n",
        "TARGET_COL = WINDOW_SIZE//2\n",
        "\n",
        "DTYPE = 'float32'\n",
        "\n",
        "# cqt related\n",
        "FFT_BINS = 768 # function of items below\n",
        "HOP_LENGTH = 256\n",
        "\n",
        "# stft values\n",
        "N_FFT = 1024 # 512 recommended for speech, music typically 2048\n",
        "\n",
        "# cqt values\n",
        "BINS_PER_OCTAVE = 12 * 8\n",
        "FMIN = librosa.note_to_hz('C1')\n",
        "OCTAVES = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MUhAB8HrkTwP",
        "colab": {}
      },
      "source": [
        "# Idea here is that we operate on magnitude, and will just use phase from the original noisy sample\n",
        "\n",
        "def combine_target(t):\n",
        "    return (t[0:t.shape[0]//2] + 1j * t[t.shape[0]//2:]).reshape(1,(t.shape[0]//2))\n",
        "\n",
        "def rebuild_fft(output, original_fft):\n",
        "    vphase = np.vectorize(cmath.phase)\n",
        "    o_phase = vphase(original_fft)\n",
        "    mag = output.T\n",
        "    vrect = np.vectorize(cmath.rect)\n",
        "    return vrect(mag, o_phase)\n",
        "    \n",
        "# build up as (bins, samples) then transpose to model view of (samples, bins)\n",
        "def targets_to_fft(targets):\n",
        "    fft = np.empty((targets.shape[0],targets.shape[1]//2), dtype='complex64')\n",
        "    for i in range(0, targets.shape[0]):\n",
        "        fft[i] = combine_target(targets[i])\n",
        "    return fft.T   # transpose\n",
        "\n",
        "def get_ft(wav):\n",
        "    c = librosa.cqt(wav, hop_length=HOP_LENGTH, fmin=FMIN, n_bins=OCTAVES*BINS_PER_OCTAVE, bins_per_octave=BINS_PER_OCTAVE)\n",
        "    #c = librosa.stft(wav, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
        "    return c\n",
        "\n",
        "def inv_ft(ft):\n",
        "    return librosa.icqt(ft, hop_length=HOP_LENGTH, bins_per_octave=BINS_PER_OCTAVE)\n",
        "    #return librosa.istft(ft, hop_length=HOP_LENGTH)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0mgM7ZVjlStg",
        "colab": {}
      },
      "source": [
        "# For local data\n",
        "samples=100000\n",
        "frames = np.memmap(\"f://audiodata//fsamples-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 1))\n",
        "targets = np.memmap(\"f://audiodata//ftargets-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xFRoJVK1VqiE",
        "colab": {}
      },
      "source": [
        "# For collab data\n",
        "samples = 300000\n",
        "frames = np.memmap(\"fsamples-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 1))\n",
        "targets = np.memmap(\"ftargets-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ur6yJmzVkTwc",
        "colab": {}
      },
      "source": [
        "# Code to generate input, target, and verification data\n",
        "# From https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, input_array, target_array, batch_size=32, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.input_array = input_array\n",
        "        self.target_array = target_array\n",
        "        self.dim = (WINDOW_SIZE,FFT_BINS) # Input data shape\n",
        "        self.batch_size = batch_size\n",
        "        self.list_IDs = list_IDs  # the set of allowed IDs to use as addresses for frames and target samples\n",
        "        self.n_channels = 1\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size, FFT_BINS), dtype=DTYPE)\n",
        "\n",
        "        # Generate data\n",
        "        half_win = WINDOW_SIZE // 2\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample & target\n",
        "            X[i,] = self.input_array[ID-half_win:ID+half_win+1,:,:]\n",
        "            y[i] = self.target_array[ID,:]\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJq_FBWlVqiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the generator\n",
        "validation_split = 0.05\n",
        "batch_size = 64\n",
        "\n",
        "# Available IDs\n",
        "all_IDs = np.arange(WINDOW_SIZE//2, frames.shape[0]-WINDOW_SIZE//2)\n",
        "np.random.shuffle(all_IDs)\n",
        "\n",
        "validation_cut = int(np.floor(len(all_IDs) * (1-validation_split)))\n",
        "validation_IDs = all_IDs[validation_cut:]\n",
        "train_IDs = all_IDs[0:validation_cut-1]\n",
        "\n",
        "training_generator = DataGenerator(train_IDs, frames, targets, batch_size=batch_size)\n",
        "validation_generator = DataGenerator(validation_IDs, frames, targets, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ibbfUgj5kTwf",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# Real model (eventually)\n",
        "ALPHA = 0.05\n",
        "L2Reg = 0.00000 # bumping this up to 0.000005 didn't seem very good\n",
        "\n",
        "inputs = layers.Input(shape=(WINDOW_SIZE,FFT_BINS,1)) # Full window\n",
        "\n",
        "NARROW_VIEW = 15\n",
        "\n",
        "# WARNING - if I put a constant in the lambda function, it causes an error when loading the model\n",
        "def sub_samples(samples, n, window_size):\n",
        "    half_cut = (window_size - n) // 2\n",
        "    return samples[:,half_cut:-half_cut,:,:]\n",
        "    \n",
        "# process inputs into subsets of interest\n",
        "input_slice = layers.Lambda(sub_samples, arguments = {'n':1, 'window_size':WINDOW_SIZE}, name=\"targetslice\")(inputs)\n",
        "narrow_view = layers.Lambda(sub_samples, arguments = {'n':NARROW_VIEW, 'window_size':WINDOW_SIZE}, name=\"narrow_view\")(inputs)\n",
        "\n",
        "# zoomed out view\n",
        "broad_pool1 = layers.AveragePooling2D(pool_size=(3,5), strides=(2,3), name=\"broad_pool1\")(inputs)\n",
        "broad_conv1 = layers.Conv2D(64, kernel_size=(5,BINS_PER_OCTAVE//5), strides=(2,BINS_PER_OCTAVE//20), activity_regularizer=regularizers.l2(L2Reg), name=\"broad_conv1\")(broad_pool1)\n",
        "bc1a = layers.LeakyReLU(alpha=ALPHA)(broad_conv1)\n",
        "broad_conv2 = layers.Conv2D(32, kernel_size=(3,4), strides=(1,4), activity_regularizer=regularizers.l2(L2Reg), name=\"broad_conv2\")(bc1a)\n",
        "bc2a = layers.LeakyReLU(alpha=ALPHA)(broad_conv2)\n",
        "broad_pool2 = layers.MaxPooling2D(pool_size=(1,4), strides=(1,2), name=\"broad_pool2\")(bc2a)\n",
        "bp2a = layers.LeakyReLU(alpha=ALPHA)(broad_pool2)\n",
        "flat_b = layers.Flatten(name=\"flat_b\")(bp2a)\n",
        "\n",
        "# narrow view\n",
        "conv1 = layers.Conv2D(128, kernel_size=(3,BINS_PER_OCTAVE), strides=(1,BINS_PER_OCTAVE//4), activity_regularizer=regularizers.l2(L2Reg), name=\"conv1\")(narrow_view)\n",
        "c1a = layers.LeakyReLU(alpha=ALPHA)(conv1)\n",
        "conv2 = layers.Conv2D(64, kernel_size=(3,4), strides=(1,2), activity_regularizer=regularizers.l2(L2Reg), name=\"conv2\")(c1a)\n",
        "c2a = layers.LeakyReLU(alpha=ALPHA)(conv2)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1,8), strides=(1,4), name=\"pool1\")(c2a)\n",
        "p1a = layers.LeakyReLU(alpha=ALPHA)(pool1)\n",
        "flat_n = layers.Flatten(name=\"flat_n\")(p1a)\n",
        "\n",
        "# Vertical features - across samples then bins\n",
        "#conv3 = layers.Conv2D(64, kernel_size=(3,30), activity_regularizer=regularizers.l2(L2Reg), name=\"conv3\")(inputs) \n",
        "#c3a = layers.LeakyReLU(alpha=ALPHA)(conv3)\n",
        "#flat_v = layers.Flatten(name=\"flat_v\")(c3a)\n",
        "\n",
        "flat = layers.concatenate([flat_b, flat_n], name=\"merge_modes\")\n",
        "\n",
        "flat_in = layers.Flatten(name=\"flatten\")(input_slice)\n",
        "\n",
        "dense0 = layers.Dense(1000, activity_regularizer=regularizers.l2(L2Reg))(flat)\n",
        "d0a = layers.LeakyReLU(alpha=ALPHA)(dense0)\n",
        "merge1 = layers.concatenate([d0a, flat_in], name=\"merge_input\")\n",
        "\n",
        "dense1 = layers.Dense(300, activity_regularizer=regularizers.l2(L2Reg))(merge1)\n",
        "d1a = keras.layers.LeakyReLU(alpha=ALPHA)(dense1)\n",
        "#dense2 = layers.Dense(500, )(dense1)\n",
        "#d2a = keras.layers.LeakyReLU(alpha=ALPHA)(dense2)\n",
        "merged = layers.concatenate([d1a, flat_in])\n",
        "outputs = layers.Dense(FFT_BINS, activation='linear')(merged)\n",
        "\n",
        "model = keras.models.Model(inputs=[inputs], outputs=outputs)\n",
        "\n",
        "model.compile(optimizer='Adam', loss='mse')\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG4Ie6wWVqiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit_generator\n",
        "stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=15, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "save_best = keras.callbacks.ModelCheckpoint(\"Best_model.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "hist = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=5, callbacks = [stopper, save_best])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPctpbJIg6rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "now = time.strftime('%Y-%m-%d_%H-%M')\n",
        "model.save(\"model_\"+now+\".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EqG_dSiTkTwj",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "history = hist\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.ylim((0, 2 * history.history['loss'][0])) # because sometimes there are stupid spikes in error\n",
        "plt.show()\n",
        "\n",
        "#plt.savefig('test.png')\n",
        "print(\"Validation loss mean 5+ epochs {0:.4}\".format(np.mean(history.history['val_loss'][5:])))\n",
        "print(\"Lowest validation loss {0:.4}\".format(np.min(history.history['val_loss'][5:])))\n",
        "print(\"Frames \", frames.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1tuZ62OokTwl",
        "colab": {}
      },
      "source": [
        "# Not required because of 'restore best weights'\n",
        "#model = keras.models.load_model(\"Best_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-lCNToBxkTwR",
        "colab": {}
      },
      "source": [
        "# some test data to hack around with\n",
        "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\p232_010.wav\"\n",
        "wav, rate = librosa.core.load(test_file)\n",
        "fft = get_ft(wav)\n",
        "#print(fft.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c8DZfaSgkTwn",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# Full round trip test\n",
        "file = \"p232_001.wav\"\n",
        "\n",
        "verify_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\\" + file\n",
        "clean_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\\" + file\n",
        "\n",
        "\n",
        "# Sample output is (samples, bins) all converted to magnitude\n",
        "def get_samples(file):\n",
        "    wav, rate = librosa.core.load(file)\n",
        "    samples = abs(get_ft(wav).T) # organized as bins, frames so we need to transpose them to frames, bins\n",
        "    return samples\n",
        "\n",
        "# Only need this for testing at this point?  Could still make it a 'top' type shared function\n",
        "def clip_frames(file):\n",
        "    samples = get_samples(file)\n",
        "    print(samples.shape)\n",
        "    frames = np.empty((samples.shape[0], WINDOW_SIZE, FFT_BINS, 1))\n",
        "    half_win = WINDOW_SIZE//2\n",
        "    for i in range(half_win, samples.shape[0]-half_win):\n",
        "        frames[i,:,:,0] = samples[i-half_win:i+half_win+1,:]\n",
        "    return frames\n",
        "\n",
        "\n",
        "def clean_clip(model, n_file):\n",
        "    verify_frames = clip_frames(n_file)\n",
        "    output_targets = model.predict([verify_frames])\n",
        "    wav, rate = librosa.core.load(n_file)\n",
        "    n_fft = get_ft(wav)\n",
        "    fft = rebuild_fft(output_targets, n_fft)\n",
        "    return fft, inv_ft(fft)\n",
        "\n",
        "\n",
        "p_fft, p_wav = clean_clip(model, verify_file)\n",
        "    \n",
        "wav, rate = librosa.core.load(clean_file)\n",
        "c_fft = get_ft(wav)\n",
        "\n",
        "\n",
        "def display_fft(ft):\n",
        "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(ft), ref=np.max), y_axis='cqt_hz', x_axis='time')\n",
        "\n",
        "print(\"Cleaned clip\")\n",
        "\n",
        "err_fft = c_fft - p_fft\n",
        "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
        "\n",
        "display_fft(p_fft)\n",
        "Audio(p_wav,rate=22050)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sqHS_31nkTwp",
        "colab": {}
      },
      "source": [
        "def draw(wav):\n",
        "    fft = get_ft(wav)\n",
        "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='cqt_hz', x_axis='time')\n",
        "    return fft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3xhtGoYOkTwr",
        "colab": {}
      },
      "source": [
        "wav, rate = librosa.core.load(verify_file)\n",
        "n_fft = draw(wav)\n",
        "\n",
        "err_fft = c_fft - n_fft\n",
        "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
        "\n",
        "print(\"Noisy file\")\n",
        "Audio(wav, rate=rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oeyY6RDTkTwu",
        "colab": {}
      },
      "source": [
        "wav, rate = librosa.core.load(clean_file)\n",
        "c_fft = draw(wav)\n",
        "\n",
        "print(\"Clean sample\")\n",
        "Audio(wav, rate=rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zO4WwsB9kTww",
        "colab": {}
      },
      "source": [
        "cut_fft = n_fft-p_fft\n",
        "display_fft(cut_fft)\n",
        "\n",
        "print(\"Removed audio\")\n",
        "print(\"Average cut value = \", np.mean(abs(cut_fft)))\n",
        "\n",
        "cut_wav = inv_ft(cut_fft)\n",
        "Audio(cut_wav,rate=22050)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_tC3WpzokTwy",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k7wCtwF4kTw0",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "#%%capture cap\n",
        "print(model.summary())\n",
        "#with open('output.txt', 'w') as f:\n",
        "#    f.write(cap.stdout)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0b_mGnNZkTw3",
        "colab": {}
      },
      "source": [
        "fresh_wav, rate = librosa.core.load(\"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\p232_019.wav\")\n",
        "Audio(fresh_wav, rate=rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "peLEO0VZkTw6"
      },
      "source": [
        "Test & reference stuff "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BPX3_ZiMkTw7",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "ft = clip_frames(test_file)\n",
        "tt = clip_targets(test_file)\n",
        "\n",
        "print(ft.shape)\n",
        "print(tt.shape)\n",
        "\n",
        "#Frame / target check  -  don't use first row because it might be zeroed out\n",
        "r = 10\n",
        "print(tt[0,r])\n",
        "print(ft[0,r,TARGET_COL:TARGET_COL+1,0])\n",
        "\n",
        "# Round trip test\n",
        "new_fft = rebuild_fft(tt, fft)\n",
        "print(new_fft.shape)\n",
        "new_wav = inv_ft(new_fft)\n",
        "\n",
        "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='log', x_axis='time')\n",
        "\n",
        "Audio(new_wav,rate=22050)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k67NuIJQkTw-",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "    \n",
        "def show_fft(wav):\n",
        "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(librosa.stft(wav)), ref=np.max), y_axis='log', x_axis='time')\n",
        "\n",
        "def display_fft(ft):\n",
        "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='log', x_axis='time')\n",
        "\n",
        "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='log', x_axis='time')\n",
        "\n",
        "print(new_fft.shape)\n",
        "\n",
        "#show_fft(wav)\n",
        "#show_fft(new_wav)\n",
        "#Audio(wav, rate=22050)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M4HRcM0rkTxA",
        "colab": {}
      },
      "source": [
        "# Test stuff for hacking around    \n",
        "    \n",
        "a = np.array([[1+2j, 3+4j, 1.5+2.5j],[5+6j,7+8j, 5.5+6.5j]])\n",
        "print(a)\n",
        "a1 = a[0]\n",
        "print(a1)\n",
        "ar = a1.real\n",
        "ai = a1.imag\n",
        "\n",
        "st = np.zeros((6))\n",
        "st[0:3] = ar\n",
        "st[3:6] = ai\n",
        "print(ar.shape, ai.shape, st.shape)\n",
        "print(ar, ai)\n",
        "print(st)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lofx2hiEkTxC",
        "colab": {}
      },
      "source": [
        "# ''do nothing' model that should be able to guess outputs from outputs\n",
        "\n",
        "inputs = layers.Input(shape=(FFT_BINS*2,))\n",
        "dense1 = layers.Dense(2000, activation='relu')(inputs)\n",
        "dense2 = layers.Dense(2000, activation='relu')(dense1)\n",
        "#flat = layers.Flatten()(dense)\n",
        "#flat_in = layers.Flatten()(inputs)\n",
        "#merged = layers.concatenate([flat, flat_in])\n",
        "merged = layers.concatenate([dense2, inputs])\n",
        "linear = layers.Dense(2000, activation='linear')(merged)\n",
        "outputs = layers.Dense(2*FFT_BINS, activation='linear')(linear)\n",
        "\n",
        "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer='Adam', loss='mse')\n",
        "\n",
        "model.fit(targets, targets, epochs=1, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}