{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugJNGnNlkTwI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "import os\n",
    "import time\n",
    "import cmath\n",
    "\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "from keras import layers\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPWfsAnkkgxD"
   },
   "outputs": [],
   "source": [
    "# If on google colab, run this\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "os.chdir('drive/My Drive/Projects/Audio Separation/Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X4ZOOJsSkTwM"
   },
   "source": [
    "Rewriten to use a single stream of data and on the fly creation of batch data\n",
    "\n",
    "TODO\n",
    "* Change name from frames to samples everywhere\n",
    "\n",
    "* Add drop out\n",
    "\n",
    "* Automatic logging of graphs, errors, models etc. for comparison\n",
    "* Add graph of model\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file='model.png')\n",
    "* Create log output function, then capture to text file (also export graphs?)\n",
    "\n",
    "* Look for sources of noise that are close to what I want?  Or generate some clips?\n",
    "\n",
    "* Debugging tools for comparing, listening to, and viewing clips\n",
    "* Add audio quality comparisons between clean clips and cleaned clips for evaluation\n",
    "\n",
    "* Add history error plotting to compare different learning models, topologies, etc.\n",
    "\n",
    "* Look into streaming frames to & from file and having way more samples\n",
    "\n",
    "* Why does https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785 only use real component?\n",
    "* Evaluate different representations of complex numbers in terms of learnability\n",
    "\n",
    "* Consider generating custom data for goal - male speakers, low voice, specific sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0NWhq04kTwN"
   },
   "outputs": [],
   "source": [
    "# Get shared constants and functions\n",
    "%run \"NN Audio Core.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mgM7ZVjlStg"
   },
   "outputs": [],
   "source": [
    "# For local data\n",
    "samples=100000\n",
    "frames = np.memmap(\"f://audiodata//fsamples-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 1))\n",
    "targets = np.memmap(\"f://audiodata//ftargets-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFRoJVK1VqiE"
   },
   "outputs": [],
   "source": [
    "# For collab data\n",
    "samples = 500000\n",
    "# for testing identity mapping\n",
    "#frames = np.memmap(\"ftargets-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 1))\n",
    "frames = np.memmap(\"fsamples-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, 1))\n",
    "targets = np.memmap(\"ftargets-\"+str(samples), mode='r', dtype=DTYPE, shape=(samples, FFT_BINS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ur6yJmzVkTwc"
   },
   "outputs": [],
   "source": [
    "# Code to generate input, target, and verification data\n",
    "# From https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, input_array, target_array, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.input_array = input_array\n",
    "        self.target_array = target_array\n",
    "        self.dim = (WINDOW_SIZE,FFT_BINS) # Input data shape\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs  # the set of allowed IDs to use as addresses for frames and target samples\n",
    "        self.n_channels = 1\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, FFT_BINS), dtype=DTYPE)\n",
    "\n",
    "        # Generate data\n",
    "        half_win = WINDOW_SIZE // 2\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample & target\n",
    "            X[i,] = self.input_array[ID-half_win:ID+half_win+1,:,:]\n",
    "            y[i] = self.target_array[ID,:]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJq_FBWlVqiJ"
   },
   "outputs": [],
   "source": [
    "# Prepare the generator\n",
    "validation_split = 0.05\n",
    "batch_size = 64\n",
    "\n",
    "# Available IDs\n",
    "all_IDs = np.arange(WINDOW_SIZE//2, frames.shape[0]-WINDOW_SIZE//2)\n",
    "np.random.shuffle(all_IDs)\n",
    "\n",
    "validation_cut = int(np.floor(len(all_IDs) * (1-validation_split)))\n",
    "validation_IDs = all_IDs[validation_cut:]\n",
    "train_IDs = all_IDs[0:validation_cut-1]\n",
    "\n",
    "training_generator = DataGenerator(train_IDs, frames, targets, batch_size=batch_size)\n",
    "validation_generator = DataGenerator(validation_IDs, frames, targets, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPnHk4p2AIpj"
   },
   "outputs": [],
   "source": [
    "# Network building functions\n",
    "def conv_set(depth, kernel, strides, name, input):\n",
    "  conv = layers.Conv2D(depth, kernel_size=kernel, strides=strides, activity_regularizer=regularizers.l2(L2Reg), name=name+\"_conv\")(input)\n",
    "  norm = layers.BatchNormalization()(conv)\n",
    "  return layers.LeakyReLU(alpha=ALPHA, name=name+\"_LRelu\")(norm)\n",
    "\n",
    "def pool_set(size, strides, name, input):\n",
    "  pool = layers.MaxPooling2D(pool_size=size, strides=strides, name=name+\"_pool\")(input)\n",
    "  return layers.LeakyReLU(alpha=ALPHA)(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibbfUgj5kTwf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Real model (eventually)\n",
    "ALPHA = 0.01\n",
    "L2Reg = 0.0000 # bumping this up to 0.000005 didn't seem very good\n",
    "\n",
    "inputs = layers.Input(shape=(WINDOW_SIZE,FFT_BINS,1)) # Full window\n",
    "\n",
    "NARROW_VIEW = 15\n",
    "\n",
    "# WARNING - if I put a constant in the lambda function, it causes an error when loading the model\n",
    "def sub_samples(samples, n, window_size):\n",
    "    half_cut = (window_size - n) // 2\n",
    "    return samples[:,half_cut:-half_cut,:,:]\n",
    "    \n",
    "# process inputs into subsets of interest\n",
    "input_slice = layers.Lambda(sub_samples, arguments = {'n':1, 'window_size':WINDOW_SIZE}, name=\"targetslice\")(inputs)\n",
    "narrow_view = layers.Lambda(sub_samples, arguments = {'n':NARROW_VIEW, 'window_size':WINDOW_SIZE}, name=\"narrow_view\")(inputs)\n",
    "\n",
    "# zoomed out view\n",
    "broad_pool1 = layers.AveragePooling2D(pool_size=(3,7), strides=(2,4), name=\"broad_pool1\")(inputs)\n",
    "broad_conv1 = conv_set(128,(5,20), (2,4), \"bconv1\", broad_pool1)\n",
    "broad_conv2 = conv_set(64, (3,4), (1,2), \"bconv2\", broad_conv1)\n",
    "broad_pool2 = pool_set((3,5), (1,3), \"bpool2\", broad_conv2)\n",
    "broad_conv3 = conv_set(32, (4,4), (1,1), \"bconv3\", broad_pool2)\n",
    "bnorm = layers.BatchNormalization(name=\"b_norm\")(broad_conv3)\n",
    "flat_b = layers.Flatten(name=\"flat_b\")(bnorm)\n",
    "\n",
    "# narrow view\n",
    "conv1 = conv_set(128, (3,20), (1,5), \"conv1\", narrow_view)\n",
    "conv2 = conv_set(64, (3,6), (1,2), \"conv2\", conv1)\n",
    "pool1 = pool_set((2,8), (1,4), \"pool1\", conv2)\n",
    "conv3 = conv_set(32, (3,4), (1,1), \"conv3\", pool1)\n",
    "nnorm = layers.BatchNormalization(name=\"n_norm\")(conv3)\n",
    "flat_n = layers.Flatten(name=\"flat_n\")(nnorm)\n",
    "\n",
    "flat = layers.concatenate([flat_b, flat_n], name=\"merge_modes\")\n",
    "\n",
    "flat_in = layers.Flatten(name=\"flatten\")(input_slice)\n",
    "\n",
    "dense0 = layers.Dense(700, activity_regularizer=regularizers.l2(L2Reg))(flat)\n",
    "d0a = layers.LeakyReLU(alpha=ALPHA)(dense0)\n",
    "merge1 = layers.concatenate([d0a, flat_in], name=\"merge_input\")\n",
    "\n",
    "dense1 = layers.Dense(500, activity_regularizer=regularizers.l2(L2Reg))(merge1)\n",
    "d1a = keras.layers.LeakyReLU(alpha=ALPHA)(dense1)\n",
    "dense2 = layers.Dense(300, )(d1a)\n",
    "d2a = keras.layers.LeakyReLU(alpha=ALPHA)(dense2)\n",
    "merged = layers.concatenate([d2a, flat_in])\n",
    "outputs = layers.Dense(FFT_BINS, activation='linear')(merged)\n",
    "\n",
    "model = keras.models.Model(inputs=[inputs], outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ErQAka1B6A1"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "from IPython.display import Image\n",
    "Image(retina=True, filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zG4Ie6wWVqiQ"
   },
   "outputs": [],
   "source": [
    "# fit_generator\n",
    "stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "save_best = keras.callbacks.ModelCheckpoint(\"Best_model.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# Max queue size is to fix \"UserWarning: The input 6833 could not be retrieved. It could be because a worker has died.\"\n",
    "#  10 didn't work once for 500K samples, 1025 bins but tried 5 and that seemed to\n",
    "hist = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=2, callbacks = [stopper, save_best], max_queue_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPctpbJIg6rC"
   },
   "outputs": [],
   "source": [
    "now = time.strftime('%Y-%m-%d_%H-%M')\n",
    "model.save(\"model_\"+now+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqG_dSiTkTwj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = hist\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.ylim((0, 2 * history.history['loss'][0])) # because sometimes there are stupid spikes in error\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('test.png')\n",
    "print(\"Validation loss mean 5+ epochs {0:.4}\".format(np.mean(history.history['val_loss'][5:])))\n",
    "print(\"Lowest validation loss {0:.4}\".format(np.min(history.history['val_loss'][5:])))\n",
    "print(\"Frames \", frames.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lCNToBxkTwR"
   },
   "outputs": [],
   "source": [
    "# some test data to hack around with\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\p232_010.wav\"\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "fft = get_ft(wav)\n",
    "#print(fft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8DZfaSgkTwn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Full round trip test\n",
    "file = \"p232_001.wav\"\n",
    "\n",
    "verify_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\\" + file\n",
    "clean_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\\" + file\n",
    "\n",
    "\n",
    "# Sample output is (samples, bins) all converted to magnitude\n",
    "def get_samples(file):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    samples = abs(get_ft(wav).T) # organized as bins, frames so we need to transpose them to frames, bins\n",
    "    return samples\n",
    "\n",
    "# Only need this for testing at this point?  Could still make it a 'top' type shared function\n",
    "def clip_frames(file):\n",
    "    samples = get_samples(file)\n",
    "    print(samples.shape)\n",
    "    frames = np.empty((samples.shape[0], WINDOW_SIZE, FFT_BINS, 1))\n",
    "    half_win = WINDOW_SIZE//2\n",
    "    for i in range(half_win, samples.shape[0]-half_win):\n",
    "        frames[i,:,:,0] = samples[i-half_win:i+half_win+1,:]\n",
    "    return frames\n",
    "\n",
    "\n",
    "def clean_clip(model, n_file):\n",
    "    verify_frames = clip_frames(n_file)\n",
    "    output_targets = model.predict([verify_frames])\n",
    "    wav, rate = librosa.core.load(n_file)\n",
    "    n_fft = get_ft(wav)\n",
    "    fft = rebuild_fft(output_targets, n_fft)\n",
    "    return fft, inv_ft(fft)\n",
    "\n",
    "\n",
    "p_fft, p_wav = clean_clip(model, verify_file)\n",
    "    \n",
    "wav, rate = librosa.core.load(clean_file)\n",
    "c_fft = get_ft(wav)\n",
    "\n",
    "\n",
    "def display_fft(ft):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(ft), ref=np.max), y_axis='cqt_hz', x_axis='time')\n",
    "\n",
    "print(\"Cleaned clip\")\n",
    "\n",
    "err_fft = c_fft - p_fft\n",
    "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
    "\n",
    "display_fft(p_fft)\n",
    "Audio(p_wav,rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqHS_31nkTwp"
   },
   "outputs": [],
   "source": [
    "def draw(wav):\n",
    "    fft = get_ft(wav)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='cqt_hz', x_axis='time')\n",
    "    return fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xhtGoYOkTwr"
   },
   "outputs": [],
   "source": [
    "wav, rate = librosa.core.load(verify_file)\n",
    "n_fft = draw(wav)\n",
    "\n",
    "err_fft = c_fft - n_fft\n",
    "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
    "\n",
    "print(\"Noisy file\")\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeyY6RDTkTwu"
   },
   "outputs": [],
   "source": [
    "wav, rate = librosa.core.load(clean_file)\n",
    "c_fft = draw(wav)\n",
    "\n",
    "print(\"Clean sample\")\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zO4WwsB9kTww"
   },
   "outputs": [],
   "source": [
    "cut_fft = n_fft-p_fft\n",
    "display_fft(cut_fft)\n",
    "\n",
    "print(\"Removed audio\")\n",
    "print(\"Average cut value = \", np.mean(abs(cut_fft)))\n",
    "\n",
    "cut_wav = inv_ft(cut_fft)\n",
    "Audio(cut_wav,rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tC3WpzokTwy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7wCtwF4kTw0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%capture cap\n",
    "print(model.summary())\n",
    "#with open('output.txt', 'w') as f:\n",
    "#    f.write(cap.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0b_mGnNZkTw3"
   },
   "outputs": [],
   "source": [
    "fresh_wav, rate = librosa.core.load(\"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\p232_019.wav\")\n",
    "Audio(fresh_wav, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peLEO0VZkTw6"
   },
   "source": [
    "Test & reference stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPX3_ZiMkTw7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ft = clip_frames(test_file)\n",
    "tt = clip_targets(test_file)\n",
    "\n",
    "print(ft.shape)\n",
    "print(tt.shape)\n",
    "\n",
    "#Frame / target check  -  don't use first row because it might be zeroed out\n",
    "r = 10\n",
    "print(tt[0,r])\n",
    "print(ft[0,r,TARGET_COL:TARGET_COL+1,0])\n",
    "\n",
    "# Round trip test\n",
    "new_fft = rebuild_fft(tt, fft)\n",
    "print(new_fft.shape)\n",
    "new_wav = inv_ft(new_fft)\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "Audio(new_wav,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k67NuIJQkTw-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "def show_fft(wav):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(librosa.stft(wav)), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "def display_fft(ft):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "print(new_fft.shape)\n",
    "\n",
    "#show_fft(wav)\n",
    "#show_fft(new_wav)\n",
    "#Audio(wav, rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4HRcM0rkTxA"
   },
   "outputs": [],
   "source": [
    "# Test stuff for hacking around    \n",
    "    \n",
    "a = np.array([[1+2j, 3+4j, 1.5+2.5j],[5+6j,7+8j, 5.5+6.5j]])\n",
    "print(a)\n",
    "a1 = a[0]\n",
    "print(a1)\n",
    "ar = a1.real\n",
    "ai = a1.imag\n",
    "\n",
    "st = np.zeros((6))\n",
    "st[0:3] = ar\n",
    "st[3:6] = ai\n",
    "print(ar.shape, ai.shape, st.shape)\n",
    "print(ar, ai)\n",
    "print(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lofx2hiEkTxC"
   },
   "outputs": [],
   "source": [
    "# ''do nothing' model that should be able to guess outputs from outputs\n",
    "\n",
    "inputs = layers.Input(shape=(FFT_BINS*2,))\n",
    "dense1 = layers.Dense(2000, activation='relu')(inputs)\n",
    "dense2 = layers.Dense(2000, activation='relu')(dense1)\n",
    "#flat = layers.Flatten()(dense)\n",
    "#flat_in = layers.Flatten()(inputs)\n",
    "#merged = layers.concatenate([flat, flat_in])\n",
    "merged = layers.concatenate([dense2, inputs])\n",
    "linear = layers.Dense(2000, activation='linear')(merged)\n",
    "outputs = layers.Dense(2*FFT_BINS, activation='linear')(linear)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "model.fit(targets, targets, epochs=1, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NN Audio Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
