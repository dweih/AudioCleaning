{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugJNGnNlkTwI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "# This is to force CPU evaluation since we probably train on a bigger GPU than I have\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "#import time\n",
    "import cmath\n",
    "\n",
    "import keras\n",
    "#import keras.layers as layers\n",
    "#from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "from keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0NWhq04kTwN"
   },
   "outputs": [],
   "source": [
    "# Constants and settings\n",
    "WINDOW_SIZE = 55  # Has to be odd\n",
    "TARGET_COL = WINDOW_SIZE//2\n",
    "\n",
    "DTYPE = 'float32'\n",
    "\n",
    "# stft values\n",
    "N_FFT = 1024 # 512 recommended for speech, music typically 2048\n",
    "FFT_BINS = 513\n",
    "\n",
    "# cqt values\n",
    "#FFT_BINS = 768 # function of items below\n",
    "HOP_LENGTH = 256\n",
    "\n",
    "BINS_PER_OCTAVE = 12 * 8\n",
    "FMIN = librosa.note_to_hz('C1')\n",
    "OCTAVES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUhAB8HrkTwP"
   },
   "outputs": [],
   "source": [
    "# Idea here is that we operate on magnitude, and will just use phase from the original noisy sample\n",
    "\n",
    "#def combine_target(t):\n",
    "#    return (t[0:t.shape[0]//2] + 1j * t[t.shape[0]//2:]).reshape(1,(t.shape[0]//2))\n",
    "\n",
    "# Original FFT is from noisy file, and used to get phase information since we only train on magnitude\n",
    "def rebuild_fft(output, original_fft):\n",
    "    vphase = np.vectorize(cmath.phase)\n",
    "    o_phase = vphase(original_fft)\n",
    "    mag = output.T\n",
    "    vrect = np.vectorize(cmath.rect)\n",
    "    return vrect(mag, o_phase)\n",
    "    \n",
    "# build up as (bins, samples) then transpose to model view of (samples, bins)\n",
    "#def targets_to_fft(targets):\n",
    "#    fft = np.empty((targets.shape[0],targets.shape[1]//2), dtype='complex64')\n",
    "#    for i in range(0, targets.shape[0]):\n",
    "#        fft[i] = combine_target(targets[i])\n",
    "#    return fft.T   # transpose\n",
    "\n",
    "def get_ft(wav):\n",
    "    #c = librosa.cqt(wav, hop_length=HOP_LENGTH, fmin=FMIN, n_bins=OCTAVES*BINS_PER_OCTAVE, bins_per_octave=BINS_PER_OCTAVE)\n",
    "    c = librosa.stft(wav, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "    return c\n",
    "\n",
    "def inv_ft(ft):\n",
    "    #return librosa.icqt(ft, hop_length=HOP_LENGTH, bins_per_octave=BINS_PER_OCTAVE)\n",
    "    return librosa.istft(ft, hop_length=HOP_LENGTH)\n",
    "    \n",
    "# Sample output is (samples, bins) all converted to magnitude\n",
    "def get_samples(file):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    samples = abs(get_ft(wav).T) # organized as bins, frames so we need to transpose them to frames, bins\n",
    "    return samples\n",
    "\n",
    "# Only need this for testing at this point?  Could still make it a 'top' type shared function\n",
    "def clip_frames(file):\n",
    "    samples = get_samples(file)\n",
    "    frames = np.empty((samples.shape[0], WINDOW_SIZE, FFT_BINS, 1))\n",
    "    half_win = WINDOW_SIZE//2\n",
    "    padded_samples = np.concatenate([np.zeros((half_win, FFT_BINS)), samples, np.zeros((half_win, FFT_BINS))])\n",
    "    for i in range(0, samples.shape[0]-1):\n",
    "        frames[i,:,:,0] = padded_samples[i:i+WINDOW_SIZE,:]\n",
    "    return frames\n",
    "\n",
    "\n",
    "def display_fft(ft):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(ft), ref=np.max), y_axis='cqt_hz', x_axis='time')\n",
    "\n",
    "def draw(wav):\n",
    "    fft = get_ft(wav)\n",
    "    display_fft(fft)\n",
    "    return fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lCNToBxkTwR"
   },
   "outputs": [],
   "source": [
    "# some test data to hack around with\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\p232_010.wav\"\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "ft = get_ft(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tuZ62OokTwl"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model_2020-01-19_00-35.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8DZfaSgkTwn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Full round trip test\n",
    "#p232_010.wav 255.10405\n",
    "#p232_032.wav 272.7092\n",
    "#p232_036.wav 181.75201\n",
    "#p232_044.wav 202.59595\n",
    "#p232_052.wav 287.47137\n",
    "#p232_056.wav 212.78235\n",
    "#p232_096.wav 252.29623\n",
    "#p232_160.wav 316.75772\n",
    "file = \"p232_010.wav\"\n",
    "\n",
    "verify_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\\" + file\n",
    "clean_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\\" + file\n",
    "\n",
    "\n",
    "def clean_clip(model, n_file):\n",
    "    verify_frames = clip_frames(n_file)\n",
    "    output_targets = model.predict([verify_frames])\n",
    "    wav, rate = librosa.core.load(n_file)\n",
    "    n_fft = get_ft(wav)\n",
    "    fft = rebuild_fft(output_targets, n_fft)\n",
    "    return fft, inv_ft(fft)\n",
    "\n",
    "\n",
    "p_fft, p_wav = clean_clip(model, verify_file)\n",
    "    \n",
    "wav, rate = librosa.core.load(clean_file)\n",
    "c_fft = get_ft(wav)\n",
    "\n",
    "\n",
    "print(\"Cleaned clip\")\n",
    "\n",
    "err_fft = c_fft - p_fft\n",
    "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
    "\n",
    "display_fft(p_fft)\n",
    "Audio(p_wav,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xhtGoYOkTwr"
   },
   "outputs": [],
   "source": [
    "wav, rate = librosa.core.load(verify_file)\n",
    "n_fft = draw(wav)\n",
    "\n",
    "err_fft = c_fft - n_fft\n",
    "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
    "\n",
    "print(\"Noisy file\")\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeyY6RDTkTwu"
   },
   "outputs": [],
   "source": [
    "wav, rate = librosa.core.load(clean_file)\n",
    "c_fft = draw(wav)\n",
    "\n",
    "print(\"Clean sample\")\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zO4WwsB9kTww"
   },
   "outputs": [],
   "source": [
    "cut_fft = n_fft-p_fft\n",
    "display_fft(cut_fft)\n",
    "\n",
    "print(\"Removed audio\")\n",
    "print(\"Average cut value = \", np.mean(abs(cut_fft)))\n",
    "\n",
    "cut_wav = inv_ft(cut_fft)\n",
    "Audio(cut_wav,rate=22050)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification of ability to rebuild clean from noisy clip and perfect clean magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round trip test with no NN evaluation to test pipeline\n",
    "# Have to get phase information from the noisy file to match what happens for real\n",
    "\n",
    "file = \"p232_013.wav\"\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\\" + file\n",
    "noisy_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\\" + file\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "noisy_wav, rate = librosa.core.load(noisy_file)\n",
    "\n",
    "noisy_ft = get_ft(noisy_wav)\n",
    "samples = get_samples(test_file)\n",
    "\n",
    "rt_ft = rebuild_fft(samples, noisy_ft)\n",
    "\n",
    "rt_wav = inv_ft(rt_ft)\n",
    "print(rt_ft.shape)\n",
    "\n",
    "display_fft(rt_ft)\n",
    "Audio(rt_wav,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_fft(get_ft(wav))\n",
    "Audio(wav,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NN Audio Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
