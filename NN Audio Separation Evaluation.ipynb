{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugJNGnNlkTwI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "# This is to force CPU evaluation since we probably train on a bigger GPU than I have\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0NWhq04kTwN"
   },
   "outputs": [],
   "source": [
    "# Get shared constants and functions\n",
    "%run \"NN Audio Core.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUhAB8HrkTwP"
   },
   "outputs": [],
   "source": [
    "# Functions local to this notebook\n",
    "\n",
    "# Sample output is (samples, bins) all converted to magnitude\n",
    "def get_samples(file):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    samples = abs(get_ft(wav).T) # organized as bins, frames so we need to transpose them to frames, bins\n",
    "    return samples\n",
    "\n",
    "# Only need this for testing at this point?  Could still make it a 'top' type shared function\n",
    "def clip_frames(file):\n",
    "    samples = get_samples(file)\n",
    "    frames = np.empty((samples.shape[0], WINDOW_SIZE, FFT_BINS, 1))\n",
    "    half_win = WINDOW_SIZE//2\n",
    "    padded_samples = np.concatenate([np.zeros((half_win, FFT_BINS)), samples, np.zeros((half_win, FFT_BINS))])\n",
    "    for i in range(0, samples.shape[0]-1):\n",
    "        frames[i,:,:,0] = padded_samples[i:i+WINDOW_SIZE,:]\n",
    "    return frames\n",
    "\n",
    "def display_fft(ft):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(ft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "def draw(wav):\n",
    "    fft = get_ft(wav)\n",
    "    display_fft(fft)\n",
    "    return fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lCNToBxkTwR"
   },
   "outputs": [],
   "source": [
    "# some test data to hack around with\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\p232_010.wav\"\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "ft = get_ft(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tuZ62OokTwl"
   },
   "outputs": [],
   "source": [
    "del model  # Just to be sure, since sometimes the errors didn't seem to change much on reload\n",
    "model = keras.models.load_model(\"Best_cqt_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8DZfaSgkTwn"
   },
   "outputs": [],
   "source": [
    "def diff_clip(wav_root, file):\n",
    "    clean_dir = wav_root + \"\\\\Clean\\\\\"\n",
    "    noisy_dir = wav_root + \"\\\\Noisy\\\\\"\n",
    "    noisy_ft = get_ft_from_file(noisy_dir + file)\n",
    "    clean_ft = get_ft_from_file(clean_dir + file)\n",
    "    diff = diff_ft(clean_ft, noisy_ft)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def clean_clip(model, n_file):\n",
    "    verify_frames = clip_frames(n_file)\n",
    "    output_targets = model.predict([verify_frames])\n",
    "    wav, rate = librosa.core.load(n_file)\n",
    "    n_fft = get_ft(wav)\n",
    "    fft = rebuild_fft(output_targets, n_fft)\n",
    "    return fft, inv_ft(fft)\n",
    "\n",
    "# For now just skipping below minimum files, which means we may not get exact count of results\n",
    "def compare_files(wav_root, model, n_files=50, min_origin_diff=20):\n",
    "    clean_dir = wav_root + \"\\\\Clean\\\\\"\n",
    "    noisy_dir = wav_root + \"\\\\Noisy\\\\\"\n",
    "    file_list = os.listdir(clean_dir)\n",
    "    file_index = 0\n",
    "    count = min(n_files, len(file_list))\n",
    "    diff_ratios = np.empty((0,3))\n",
    "    while (file_index < count) :\n",
    "        file = file_list[file_index]\n",
    "        #original_diff =30 + file_index\n",
    "        noisy_ft = get_ft_from_file(noisy_dir + file)\n",
    "        clean_ft = get_ft_from_file(clean_dir + file)\n",
    "        original_diff = diff_ft(clean_ft, noisy_ft)\n",
    "        if (original_diff > min_origin_diff):\n",
    "            model_ft, wav = clean_clip(model, noisy_dir + file)\n",
    "            model_diff = diff_ft(model_ft, clean_ft)\n",
    "            #model_diff = 2 * file_index\n",
    "            diff_ratios = np.append(diff_ratios,np.array([[original_diff,model_diff,model_diff/original_diff]]), axis=0)\n",
    "            print(\"%s  :  original %3.2f  :  cleaned %3.2f  :  ratio %.2f\" %(file, original_diff, model_diff, model_diff/original_diff))\n",
    "        file_index += 1\n",
    "    ratios = pd.Series(diff_ratios[:,2])\n",
    "    print(\"\\nRatios\")\n",
    "    print(\"Average: %.2f\" % np.average(ratios))\n",
    "    print(\"Percentiles\")\n",
    "    print(ratios.quantile([.25, .5, .75, .8, .9]))\n",
    "    model_scores = pd.Series(diff_ratios[:,1])\n",
    "    print(\"\\nModel noise scores\")\n",
    "    print(\"Average: %.2f\" % np.average(model_scores))\n",
    "    print(\"Percentiles\")\n",
    "    print(model_scores.quantile([.25, .5, .75, .8, .9]))\n",
    "    pr = pd.DataFrame(diff_ratios, columns=['Original', 'Cleaned', 'Ratio'])\n",
    "    pr['Original'] = pd.cut(pr['Original'], bins=[0,50,100,150,200,250,300,500])\n",
    "    pr.boxplot(by='Original', column=['Cleaned'])\n",
    "    return pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dr = compare_files(\"Assets\\\\DataShareArchive\\\\Test\\\\\", model, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.boxplot(by='Original', column=['Ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8DZfaSgkTwn",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_7 to have shape (55, 768, 2) but got array with shape (55, 768, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-169-a3b947facfa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclean_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"Clean\\\\\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mp_fft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_wav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_clip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mwav\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-168-2d5fb96d86a4>\u001b[0m in \u001b[0;36mclean_clip\u001b[1;34m(model, n_file)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_clip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mverify_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0moutput_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mverify_frames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mwav\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mn_fft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_7 to have shape (55, 768, 2) but got array with shape (55, 768, 1)"
     ]
    }
   ],
   "source": [
    "# Full round trip test\n",
    "# \"p232_005.wav\" - nice train noise\n",
    "file = \"p232_005.wav\"\n",
    "\n",
    "path = \"Assets\\\\DataShareArchive\\\\Test\\\\\"\n",
    "\n",
    "verify_file = path + \"Noisy\\\\\" + file\n",
    "clean_file = path + \"Clean\\\\\" + file\n",
    "\n",
    "p_fft, p_wav = clean_clip(model, verify_file)\n",
    "\n",
    "wav, rate = librosa.core.load(clean_file)\n",
    "c_fft = get_ft(wav)\n",
    "\n",
    "cleaned_diff = diff_ft(p_fft, c_fft)\n",
    "original_diff = diff_clip(path, file)\n",
    "ratio = cleaned_diff / original_diff\n",
    "\n",
    "print(\"Cleaned diff  %.2f\" % cleaned_diff)\n",
    "print(\"Original diff %.2f\" % original_diff)\n",
    "print(\"Ratio         %.2f\" % ratio)\n",
    "\n",
    "print(\"Cleaned clip\")\n",
    "\n",
    "display_fft(p_fft)\n",
    "Audio(p_wav,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xhtGoYOkTwr"
   },
   "outputs": [],
   "source": [
    "wav, rate = librosa.core.load(verify_file)\n",
    "n_fft = draw(wav)\n",
    "\n",
    "err_fft = c_fft - n_fft\n",
    "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
    "\n",
    "print(\"Noisy file\")\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zO4WwsB9kTww"
   },
   "outputs": [],
   "source": [
    "cut_fft = n_fft-p_fft\n",
    "display_fft(cut_fft)\n",
    "\n",
    "print(\"Removed audio\")\n",
    "print(\"Average cut value = \", np.mean(abs(cut_fft)))\n",
    "\n",
    "cut_wav = inv_ft(cut_fft)\n",
    "Audio(cut_wav,rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeyY6RDTkTwu"
   },
   "outputs": [],
   "source": [
    "wav, rate = librosa.core.load(clean_file)\n",
    "c_fft = draw(wav)\n",
    "\n",
    "print(\"Clean sample\")\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification of ability to rebuild clean from noisy clip and perfect clean magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round trip test with no NN evaluation to test pipeline\n",
    "# Have to get phase information from the noisy file to match what happens for real\n",
    "\n",
    "file = \"p232_013.wav\"\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\\" + file\n",
    "noisy_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\\" + file\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "noisy_wav, rate = librosa.core.load(noisy_file)\n",
    "\n",
    "noisy_ft = get_ft(noisy_wav)\n",
    "samples = get_samples(test_file)\n",
    "\n",
    "rt_ft = rebuild_fft(samples, noisy_ft)\n",
    "\n",
    "rt_wav = inv_ft(rt_ft)\n",
    "print(rt_ft.shape)\n",
    "\n",
    "display_fft(rt_ft)\n",
    "Audio(rt_wav,rate=22050)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NN Audio Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
