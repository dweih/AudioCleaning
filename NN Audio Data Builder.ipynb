{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import cmath\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and settings\n",
    "WINDOW_SIZE = 25  # Has to be odd\n",
    "TARGET_COL = WINDOW_SIZE//2\n",
    "\n",
    "DTYPE = 'float32'\n",
    "\n",
    "# cqt related\n",
    "FFT_BINS = 768 # function of items below\n",
    "HOP_LENGTH = 128 # Required for good cqt results\n",
    "\n",
    "# stft values\n",
    "N_FFT = 1024 # 512 recommended for speech, music typically 2048\n",
    "\n",
    "# cqt values\n",
    "BINS_PER_OCTAVE = 12 * 8\n",
    "FMIN = librosa.note_to_hz('C1')\n",
    "OCTAVES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea here is that we operate on magnitude, and will just use phase from the original noisy sample\n",
    "\n",
    "#def combine_target(t):\n",
    "#    return (t[0:t.shape[0]//2] + 1j * t[t.shape[0]//2:]).reshape(1,(t.shape[0]//2))\n",
    "\n",
    "def rebuild_fft(output, original_fft):\n",
    "    vphase = np.vectorize(cmath.phase)\n",
    "    o_phase = vphase(original_fft)\n",
    "    mag = output.T\n",
    "    vrect = np.vectorize(cmath.rect)\n",
    "    return vrect(mag, o_phase)\n",
    "    \n",
    "def get_ft(wav):\n",
    "    c = librosa.cqt(wav, hop_length=HOP_LENGTH, fmin=FMIN, n_bins=OCTAVES*BINS_PER_OCTAVE, bins_per_octave=BINS_PER_OCTAVE)\n",
    "    #c = librosa.stft(wav, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "    return c\n",
    "\n",
    "def inv_ft(ft):\n",
    "    return librosa.icqt(ft, hop_length=HOP_LENGTH, fmin=FMIN, bins_per_octave=BINS_PER_OCTAVE)\n",
    "    #return librosa.istft(ft, hop_length=HOP_LENGTH)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 477)\n"
     ]
    }
   ],
   "source": [
    "# some test data to hack around with\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\p232_010.wav\"\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "fft = get_ft(wav)\n",
    "print(fft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data from clip wave file\n",
    "# Need to get a subset of the memory mapped file to work on\n",
    "\n",
    "# Frame output is (samples, bins, window size, layers), where image is depth 2 for real & imaginary\n",
    "def clip_frames(file, frames_view):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    frame_lead = (WINDOW_SIZE-1)//2  # The amount before and after the target column\n",
    "    fft = get_ft(wav) # organized as bins, frames\n",
    "    bins = fft.shape[0]\n",
    "    max_frames = min(fft.shape[1], frames_view.shape[0])\n",
    "    pad = np.zeros((bins,frame_lead))\n",
    "    fft = np.concatenate([pad, fft, pad], axis=-1)\n",
    "    for i in range(0, max_frames):\n",
    "        frames_view[i,:,:,0] = abs(fft[:,i:i+WINDOW_SIZE])\n",
    "\n",
    "# output is array (samples, double bin length made up of real then imag)\n",
    "# Targets output is array (samples, double bin length made up of real then imag)\n",
    "def clip_targets(file, targets_view):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    frame_lead = (WINDOW_SIZE-1)//2  # The amount before and after the target column\n",
    "    fft = get_ft(wav)\n",
    "    bins = fft.shape[0]\n",
    "    for i in range(0, min(fft.shape[1], targets_view.shape[0])) :\n",
    "        targets_view[i,:] = abs(fft[:,i:i+1]).flatten()\n",
    "    return fft.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_file(data_path, max_samples):\n",
    "    frames_file = data_path + \"\\\\frames-\" + str(max_samples)\n",
    "    filename = os.fsdecode(frames_file)\n",
    "    return filename\n",
    "\n",
    "def targets_file(data_path, max_samples):\n",
    "    targets_file = data_path + \"\\\\targets-\" + str(max_samples)\n",
    "    filename = os.fsdecode(targets_file)\n",
    "    return filename\n",
    "\n",
    "# Iterate over clean & noisy folders to create frames and targets\n",
    "def create_data(wav_root, data_path, max_samples = 10000):\n",
    "    clean_dir = wav_root + \"\\\\Clean\\\\\"\n",
    "    noisy_dir = wav_root + \"\\\\Noisy\\\\\"\n",
    "    sample_index = 0\n",
    "    frames = np.memmap(frames_file(data_path, max_samples), mode='w+', dtype=DTYPE, shape=(max_samples,FFT_BINS,WINDOW_SIZE,1))\n",
    "    targets = np.memmap(targets_file(data_path, max_samples), mode='w+', dtype=DTYPE, shape=(max_samples,FFT_BINS))\n",
    "    #frames = np.empty(dtype=DTYPE, shape=(max_samples,FFT_BINS,WINDOW_SIZE,1))\n",
    "    #targets = np.empty(dtype=DTYPE, shape=(max_samples,FFT_BINS))\n",
    "    file_list = os.listdir(clean_dir)\n",
    "    file_index = 0\n",
    "    while (sample_index < max_samples) and (file_index < len(file_list)) :\n",
    "        file = file_list[file_index]\n",
    "        filename = os.fsdecode(file)\n",
    "        clip_frames(noisy_dir + file, frames[sample_index:,:,:,:])\n",
    "        sample_increment = clip_targets(clean_dir + file, targets[sample_index:,:])\n",
    "        sample_index += sample_increment\n",
    "        file_index += 1\n",
    "    print(\"Reached sample # \" + str(min(sample_index, max_samples)))\n",
    "    return frames, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached sample # 10000\n"
     ]
    }
   ],
   "source": [
    "# Training data comes in at ~ 4 * 85K samples total (changed hop size so this will have changed)\n",
    "f, t = create_data(\"Assets\\\\DataShareArchive\\\\Test\", \"f:\\\\Audiodata\", max_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 768) (50000, 768, 25, 1)\n",
      "[0.00490149]\n",
      "0.022915643\n"
     ]
    }
   ],
   "source": [
    "print(t.shape, f.shape)\n",
    "i = 2\n",
    "print(f[i,0, 12:13, 0])\n",
    "print(t[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh no i  0 , j  0    \n",
      "0.004721614  !=  0.022947581    diff  -0.018225968\n",
      "oh no i  0 , j  1    \n",
      "0.03477435  !=  0.021355934    diff  0.013418414\n",
      "oh no i  1 , j  0    \n",
      "0.0047909436  !=  0.022935083    diff  -0.01814414\n",
      "oh no i  1 , j  1    \n",
      "0.034678873  !=  0.021360101    diff  0.0133187715\n",
      "done\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "    for j in range(0,2):\n",
    "        if f[i, j, 12, 0] != t[i,j]:\n",
    "            print (\"oh no i \", i, \", j \", j, \"   \", )\n",
    "            print(f[i, j, 12, 0], \" != \", t[i,j], \"   diff \", f[i, j, 12, 0] - t[i,j])\n",
    "print(\"done\")\n",
    "print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
