{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import cmath\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and settings\n",
    "WINDOW_SIZE = 25  # Has to be odd\n",
    "TARGET_COL = WINDOW_SIZE//2\n",
    "\n",
    "DTYPE = 'float32'\n",
    "\n",
    "# cqt related\n",
    "FFT_BINS = 768 # function of items below\n",
    "HOP_LENGTH = 128 # Required for good cqt results\n",
    "\n",
    "# stft values\n",
    "N_FFT = 1024 # 512 recommended for speech, music typically 2048\n",
    "\n",
    "# cqt values\n",
    "BINS_PER_OCTAVE = 12 * 8\n",
    "FMIN = librosa.note_to_hz('C1')\n",
    "OCTAVES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea here is that we operate on magnitude, and will just use phase from the original noisy sample\n",
    "\n",
    "#def combine_target(t):\n",
    "#    return (t[0:t.shape[0]//2] + 1j * t[t.shape[0]//2:]).reshape(1,(t.shape[0]//2))\n",
    "\n",
    "def rebuild_fft(output, original_fft):\n",
    "    vphase = np.vectorize(cmath.phase)\n",
    "    o_phase = vphase(original_fft)\n",
    "    mag = output.T\n",
    "    vrect = np.vectorize(cmath.rect)\n",
    "    return vrect(mag, o_phase)\n",
    "    \n",
    "# build up as (bins, samples) then transpose to model view of (samples, bins)\n",
    "#def targets_to_fft(targets):\n",
    "#    fft = np.empty((targets.shape[0],targets.shape[1]//2), dtype='complex64')\n",
    "#    for i in range(0, targets.shape[0]):\n",
    "#        fft[i] = combine_target(targets[i])\n",
    "#    return fft.T   # transpose\n",
    "\n",
    "# May not actually use this - may want to just pass a reduced view and then add this back to get right shape\n",
    "def filter(cqt):\n",
    "    cqt[0:BINS_PER_OCTAVE,:] = 0\n",
    "    return cqt\n",
    "\n",
    "def get_ft(wav):\n",
    "    c = librosa.cqt(wav, hop_length=HOP_LENGTH, fmin=FMIN, n_bins=OCTAVES*BINS_PER_OCTAVE, bins_per_octave=BINS_PER_OCTAVE)\n",
    "    #c = librosa.stft(wav, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "    return c\n",
    "\n",
    "def inv_ft(ft):\n",
    "    return librosa.icqt(ft, hop_length=HOP_LENGTH, fmin=FMIN, bins_per_octave=BINS_PER_OCTAVE)\n",
    "    #return librosa.istft(ft, hop_length=HOP_LENGTH)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 477)\n"
     ]
    }
   ],
   "source": [
    "# some test data to hack around with\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\p232_010.wav\"\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "fft = get_ft(wav)\n",
    "print(fft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data from clip wave file\n",
    "# Need to get a subset of the memory mapped file to work on\n",
    "\n",
    "# Frame output is (samples, bins, window size, layers), where image is depth 2 for real & imaginary\n",
    "def clip_frames(file, frames_view):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    frame_lead = (WINDOW_SIZE-1)//2  # The amount before and after the target column\n",
    "    fft = get_ft(wav) # organized as bins, frames\n",
    "    bins = fft.shape[0]\n",
    "    max_frames = min(fft.shape[1], frames_view.shape[0])\n",
    "    pad = np.zeros((bins,frame_lead))\n",
    "    fft = np.concatenate([pad, fft, pad], axis=-1)\n",
    "    for i in range(0, max_frames):\n",
    "        frames_view[i,:,:,0] = abs(fft[:,i:i+WINDOW_SIZE])\n",
    "\n",
    "# output is array (samples, double bin length made up of real then imag)\n",
    "# Targets output is array (samples, double bin length made up of real then imag)\n",
    "def clip_targets(file, targets_view):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    frame_lead = (WINDOW_SIZE-1)//2  # The amount before and after the target column\n",
    "    fft = get_ft(wav)\n",
    "    bins = fft.shape[0]\n",
    "    for i in range(0, min(fft.shape[1], targets_view.shape[0])) :\n",
    "        targets_view[i,:] = abs(fft[:,i:i+1]).flatten()\n",
    "    return fft.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_file(data_path, max_samples):\n",
    "    frames_file = data_path + \"\\\\frames-\" + str(max_samples)\n",
    "    filename = os.fsdecode(frames_file)\n",
    "    return filename\n",
    "\n",
    "def targets_file(data_path, max_samples):\n",
    "    targets_file = data_path + \"\\\\targets-\" + str(max_samples)\n",
    "    filename = os.fsdecode(targets_file)\n",
    "    return filename\n",
    "\n",
    "# Iterate over clean & noisy folders to create frames and targets\n",
    "def create_data(wav_root, data_path, max_samples = 10000):\n",
    "    clean_dir = wav_root + \"\\\\Clean\\\\\"\n",
    "    noisy_dir = wav_root + \"\\\\Noisy\\\\\"\n",
    "    sample_index = 0\n",
    "    frames = np.memmap(frames_file(data_path, max_samples), mode='w+', dtype=DTYPE, shape=(max_samples,FFT_BINS,WINDOW_SIZE,1))\n",
    "    targets = np.memmap(targets_file(data_path, max_samples), mode='w+', dtype=DTYPE, shape=(max_samples,FFT_BINS))\n",
    "    #frames = np.empty(dtype=DTYPE, shape=(max_samples,FFT_BINS,WINDOW_SIZE,1))\n",
    "    #targets = np.empty(dtype=DTYPE, shape=(max_samples,FFT_BINS))\n",
    "    file_list = os.listdir(clean_dir)\n",
    "    file_index = 0\n",
    "    while (sample_index < max_samples) and (file_index < len(file_list)) :\n",
    "        file = file_list[file_index]\n",
    "        filename = os.fsdecode(file)\n",
    "        clip_frames(noisy_dir + file, frames[sample_index:,:,:,:])\n",
    "        sample_increment = clip_targets(clean_dir + file, targets[sample_index:,:])\n",
    "        sample_index += sample_increment\n",
    "        file_index += 1\n",
    "    print(\"Reached sample # \" + str(min(sample_index, max_samples)))\n",
    "    return frames, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached sample # 10000\n"
     ]
    }
   ],
   "source": [
    "# Training data comes in at ~ 4 * 85K samples total (changed hop size so this will have changed)\n",
    "f, t = create_data(\"Assets\\\\DataShareArchive\\\\Test\", \"f:\\\\Audiodata\", max_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 768) (50000, 768, 25, 1)\n",
      "[0.00490149]\n",
      "0.022915643\n"
     ]
    }
   ],
   "source": [
    "print(t.shape, f.shape)\n",
    "i = 2\n",
    "print(f[i,0, 12:13, 0])\n",
    "print(t[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh no i  0 , j  0    \n",
      "0.004721614  !=  0.022947581    diff  -0.018225968\n",
      "oh no i  0 , j  1    \n",
      "0.03477435  !=  0.021355934    diff  0.013418414\n",
      "oh no i  1 , j  0    \n",
      "0.0047909436  !=  0.022935083    diff  -0.01814414\n",
      "oh no i  1 , j  1    \n",
      "0.034678873  !=  0.021360101    diff  0.0133187715\n",
      "done\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "    for j in range(0,2):\n",
    "        if f[i, j, 12, 0] != t[i,j]:\n",
    "            print (\"oh no i \", i, \", j \", j, \"   \", )\n",
    "            print(f[i, j, 12, 0], \" != \", t[i,j], \"   diff \", f[i, j, 12, 0] - t[i,j])\n",
    "print(\"done\")\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.load(\"frames-0-500.npy\", mmap_mode='r')\n",
    "targets = np.load(\"targets-0-500.npy\", mmap_mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test & reference stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 768, 25, 1)\n",
      "(50000, 768)\n",
      "0.024500124\n",
      "[0.1009619]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (768,) (120,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ae8a1b87bd28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Round trip test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mnew_fft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrebuild_fft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfft\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_fft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mnew_wav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minv_ft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_fft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e3c3463fb9d3>\u001b[0m in \u001b[0;36mrebuild_fft\u001b[1;34m(output, original_fft)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mvrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvrect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_phase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# build up as (bins, samples) then transpose to model view of (samples, bins)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2089\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2091\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2093\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2165\u001b[0m                       for a in args]\n\u001b[0;32m   2166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2167\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2169\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (768,) (120,) "
     ]
    }
   ],
   "source": [
    "#ft = clip_frames(test_file)\n",
    "#tt = clip_targets(test_file)\n",
    "\n",
    "ft = f\n",
    "tt = t\n",
    "\n",
    "print(ft.shape)\n",
    "print(tt.shape)\n",
    "\n",
    "#Frame / target check  -  don't use first row because it might be zeroed out\n",
    "r = 10\n",
    "print(tt[0,r])\n",
    "print(ft[0,r,TARGET_COL:TARGET_COL+1,0])\n",
    "\n",
    "# Round trip test\n",
    "new_fft = rebuild_fft(tt[0,:], fft[0,:])\n",
    "print(new_fft.shape)\n",
    "new_wav = inv_ft(new_fft)\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='cqt_note', x_axis='time')\n",
    "\n",
    "Audio(new_wav,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "t = np.zeros((3,4,5))\n",
    "\n",
    "def setter(view):\n",
    "    print(view.shape)\n",
    "    view[0,0] = 1\n",
    "\n",
    "setter(t[1:2,:,3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
