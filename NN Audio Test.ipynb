{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import scipy.stats\n",
    "#import seaborn as sns\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "#import scikit_posthocs as sp\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib import gridspec\n",
    "#from matplotlib.transforms import BlendedGenericTransform\n",
    "#import scikit_posthocs as sp\n",
    "#from urllib.request import urlopen\n",
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "* Complex numbers work, but not for image processing & convolutions! Make this into a 2 deep image\n",
    "* Check alignment between center of window and targets\n",
    "* Consider edge behavior in terms of data windows (zeroes?)\n",
    "\n",
    "* Evaluate different representations of complex numbers in terms of learnability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some test data to hack around with\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\p232_010.wav\"\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "fft = librosa.stft(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and settings\n",
    "WINDOW_SIZE = 10\n",
    "FFT_BINS = 1025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_fft(fft):\n",
    "    return np.stack([fft.real, fft.imag], axis=-1)\n",
    "\n",
    "def merge_fft_img(fft_img):\n",
    "    return fft_img[:,:,0] + 1j * fft_img[:,:,1]\n",
    "\n",
    "# Creating data from clip wave file\n",
    "def clip_frames(file):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    half_win = WINDOW_SIZE//2\n",
    "    fft = librosa.stft(wav) # organized as bins, frames\n",
    "    frames = np.empty(shape=(0,FFT_BINS,WINDOW_SIZE,2)) # image is depth 2 for real & imaginary\n",
    "    for i in range(0, fft.shape[1] - WINDOW_SIZE):\n",
    "        frames = np.append(frames,[stack_fft(fft[:,i:i+WINDOW_SIZE])], axis=0)\n",
    "    return frames\n",
    "\n",
    "\n",
    "def clip_targets(file):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    half_win = WINDOW_SIZE//2\n",
    "    fft = librosa.stft(wav)\n",
    "    targets = np.empty(shape=(0,FFT_BINS))\n",
    "    for i in range(half_win, fft.shape[1] - half_win):\n",
    "        targets = np.append(targets, [fft[:,i+half_win:i+half_win+1].flatten()], axis=0)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 1025, 10, 2) (110, 1025)\n"
     ]
    }
   ],
   "source": [
    "ft = clip_frames(test_file)\n",
    "tt = clip_targets(test_file)\n",
    "print(ft.shape, tt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over clean & noisy folders to create frames and targets\n",
    "def create_data(root):\n",
    "    clean_dir = root + \"\\\\Clean\\\\\"\n",
    "    noisy_dir = root + \"\\\\Noisy\\\\\"\n",
    "    frames = np.empty(shape=(0,FFT_BINS,WINDOW_SIZE,2))\n",
    "    targets = np.empty(shape=(0,FFT_BINS))\n",
    "    for file in os.listdir(clean_dir)[0:2]:\n",
    "        filename = os.fsdecode(file)\n",
    "        frames = np.concatenate((frames,clip_frames(noisy_dir + file)), axis=0)\n",
    "        targets = np.concatenate((targets,clip_targets(clean_dir + file)), axis=0)\n",
    "    return frames, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, targets = create_data(\"Assets\\\\DataShareArchive\\\\Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define network\n",
    "\n",
    "model = keras.Sequential(\n",
    "     [\n",
    "        layers.Conv2D(16, kernel_size=2, activation='relu', padding='valid', \n",
    "                      input_shape=[FFT_BINS,WINDOW_SIZE,2]),\n",
    "        layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        layers.Conv2D(16, kernel_size=2, activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(FFT_BINS, activation='relu'),\n",
    "        layers.Dense(150, activation='relu'),\n",
    "        layers.Dense(FFT_BINS, activation='linear')\n",
    "     ]\n",
    "    )\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py:538: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 6ms/step - loss: 3.2623\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1751\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1720\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1713\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1704\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1713\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1677\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1646\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1619\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1592\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1550\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1504\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1452\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1397\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1293\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.1107\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.0969\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.0793\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.0669\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.0454\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.0256\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 3.0154\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.9862\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.9818\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.9491\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.9528\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.9103\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.8743\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.8680\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.8433\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.8111\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.8161\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.7509\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.7196\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.6760\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 2.6731\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.6423\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.5789\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.5694\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 2.5288\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.5136\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.4511\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.4257\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.4184\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.3597\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.3601\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.3294\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.2871\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.2503\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.2298\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1971\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1745\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1434\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.1396\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.0876\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.0983\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.0797\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.0433\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.0215\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 2.0014\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.9515\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.9475\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.9042\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.9096\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.8666\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.9560\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.8290\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.8247\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.8081\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.7697\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.7583\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.7555\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.7116\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.7015\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.7135\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.6681\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.6825\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.6144\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.5810\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.5968\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.6115\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.5867\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.5397\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.5489\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.5011\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.4861\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.4788\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.4977\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.4342\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.4373\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.4717\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.3843\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.3594\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.3573\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.3801\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.3974\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.2953\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.3038\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.2765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 1.2662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd4f117c48>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(frames, targets, epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] (2, 3, 0)\n",
      "[[1. +2.j  3. +4.j  1.5+2.5j]\n",
      " [5. +6.j  7. +8.j  5.5+6.5j]] (2, 3)\n",
      "[[[1.  2. ]\n",
      "  [3.  4. ]\n",
      "  [1.5 2.5]]\n",
      "\n",
      " [[5.  6. ]\n",
      "  [7.  8. ]\n",
      "  [5.5 6.5]]] (2, 3, 2)\n",
      "1.0 2.0\n"
     ]
    }
   ],
   "source": [
    "    a = np.array([[1+2j, 3+4j, 1.5+2.5j],[5+6j,7+8j, 5.5+6.5j]])\n",
    "    t = np.empty(shape=(a.shape[0],a.shape[1],0))\n",
    "    print(t,t.shape)\n",
    "    print(a,a.shape)\n",
    "    x = np.stack([a.real,a.imag], axis=-1)\n",
    "    #x = np.append(t,[a.imag,a.real], axis=-1)\n",
    "    print(x, x.shape)\n",
    "    print(x[0,0,0], x[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2., 4.],\n",
       "        [6., 8.],\n",
       "        [1., 3.],\n",
       "        [5., 7.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
