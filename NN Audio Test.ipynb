{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import scipy.stats\n",
    "#import seaborn as sns\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "#import scikit_posthocs as sp\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib import gridspec\n",
    "#from matplotlib.transforms import BlendedGenericTransform\n",
    "#import scikit_posthocs as sp\n",
    "#from urllib.request import urlopen\n",
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "* Check alignment between center of window and targets\n",
    "* Consider edge behavior in terms of data windows (zeroes?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some test data to hack around with\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\p232_010.wav\"\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "fft = librosa.stft(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and settings\n",
    "WINDOW_SIZE = 10\n",
    "FFT_BINS = 1025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data from clip wave file\n",
    "def clip_frames(file):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    half_win = WINDOW_SIZE//2\n",
    "    fft = librosa.stft(wav) # organized as bins, frames\n",
    "    frames = np.empty(shape=(0,FFT_BINS,WINDOW_SIZE))\n",
    "    for i in range(0, fft.shape[1] - WINDOW_SIZE):\n",
    "        frames = np.append(frames,[fft[:,i:i+WINDOW_SIZE]], axis=0)\n",
    "    return frames\n",
    "\n",
    "\n",
    "def clip_targets(file):\n",
    "    wav, rate = librosa.core.load(file)\n",
    "    half_win = WINDOW_SIZE//2\n",
    "    fft = librosa.stft(wav)\n",
    "    targets = np.empty(shape=(0,FFT_BINS))\n",
    "    for i in range(half_win, fft.shape[1] - half_win):\n",
    "        targets = np.append(targets, [fft[:,i+half_win:i+half_win+1].flatten()], axis=0)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 1025, 10) (110, 1025)\n"
     ]
    }
   ],
   "source": [
    "ft = clip_frames(test_file)\n",
    "tt = clip_targets(test_file)\n",
    "print(ft.shape, tt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over clean & noisy folders to create frames and targets\n",
    "def create_data(root):\n",
    "    clean_dir = root + \"\\\\Clean\\\\\"\n",
    "    noisy_dir = root + \"\\\\Noisy\\\\\"\n",
    "    frames = np.empty(shape=(0,FFT_BINS,WINDOW_SIZE))\n",
    "    targets = np.empty(shape=(0,FFT_BINS))\n",
    "    for file in os.listdir(clean_dir)[0:2]:\n",
    "        filename = os.fsdecode(file)\n",
    "        frames = np.concatenate((frames,clip_frames(noisy_dir + file)), axis=0)\n",
    "        targets = np.concatenate((targets,clip_targets(clean_dir + file)), axis=0)\n",
    "    return frames, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, targets = create_data(\"Assets\\\\DataShareArchive\\\\Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 1025)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network\n",
    "\n",
    "model = keras.Sequential(\n",
    "     [layers.Dense(FFT_BINS, activation='relu', input_shape=[FFT_BINS]),\n",
    "      layers.Dense(50, activation='relu'),\n",
    "      layers.Dense(50, activation='relu'),\n",
    "     layers.Dense(FFT_BINS, activation='linear')]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "172/172 [==============================] - 0s 388us/step - loss: 3.1067\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 319us/step - loss: 3.0355\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 2.9330\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 273us/step - loss: 2.7897\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 2.6458\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 278us/step - loss: 2.5152\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 276us/step - loss: 2.3899\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 278us/step - loss: 2.3195\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 288us/step - loss: 2.2331\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 2.1631\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 2.1247\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 2.0544\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 267us/step - loss: 1.9846\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 273us/step - loss: 1.9825\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 1.9304\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 1.8685\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 1.8039\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 296us/step - loss: 1.7535\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 302us/step - loss: 1.7224\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 0s 278us/step - loss: 1.7121\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 296us/step - loss: 1.6621\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 1.6470\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 0s 319us/step - loss: 1.6067\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 296us/step - loss: 1.5232\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 1.5323\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 278us/step - loss: 1.5005\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 273us/step - loss: 1.5431\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 273us/step - loss: 1.4114\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 293us/step - loss: 1.4830\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 307us/step - loss: 1.3585\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 319us/step - loss: 1.3512\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 307us/step - loss: 1.3617\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 278us/step - loss: 1.3207\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 0s 293us/step - loss: 1.2625\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 1.3075\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 273us/step - loss: 1.2891\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 1.2032\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 307us/step - loss: 1.2436\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 325us/step - loss: 1.2373\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 296us/step - loss: 1.1763\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 1.1629\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 307us/step - loss: 1.2104\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 296us/step - loss: 1.1652\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 1.1006\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 1.1304\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 331us/step - loss: 1.1043\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 1.0663\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 297us/step - loss: 1.0720\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 307us/step - loss: 1.0832\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 1.0833\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 267us/step - loss: 1.0411\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 278us/step - loss: 1.0233\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 348us/step - loss: 1.0699\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 0.9859\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 0.9964\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 0.9716\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 261us/step - loss: 1.0518\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 0.9738\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 273us/step - loss: 0.9738\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 0.9398\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 278us/step - loss: 0.9568\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 307us/step - loss: 0.9310\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 255us/step - loss: 0.9349\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 0.9746\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 0.9039\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 325us/step - loss: 0.9194\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 273us/step - loss: 0.9297\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 267us/step - loss: 0.8599\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 0.8763\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 307us/step - loss: 0.9085\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 296us/step - loss: 0.8964\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 325us/step - loss: 0.8719\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 255us/step - loss: 0.8244\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 278us/step - loss: 0.9402\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 260us/step - loss: 0.8102\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 0.8218\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 261us/step - loss: 0.7879\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 0.8084\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 313us/step - loss: 0.8254\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 307us/step - loss: 0.8017\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 0.8547\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 313us/step - loss: 0.7696\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 307us/step - loss: 0.7435\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 336us/step - loss: 0.7910\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 0.7740\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 284us/step - loss: 0.7442\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 0.7621\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 278us/step - loss: 0.8037\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 296us/step - loss: 0.7266\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 0.7333\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 290us/step - loss: 0.7122\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 261us/step - loss: 0.7465\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 285us/step - loss: 0.7440\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 302us/step - loss: 0.6641\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 296us/step - loss: 0.7085\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 336us/step - loss: 0.7882\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 670us/step - loss: 0.6544\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 325us/step - loss: 0.6905\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 267us/step - loss: 0.6711\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 0s 255us/step - loss: 0.6608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a3cad7e48>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(targets,targets, epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.04013502-5.551115e-17j)\n",
      "(0.16505659+1.3877788e-17j)\n"
     ]
    }
   ],
   "source": [
    "print(frames[0][5][0])\n",
    "\n",
    "print(targets[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 1)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft.shape\n",
    "fft[:,1:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p232_001.wav',\n",
       " 'p232_002.wav',\n",
       " 'p232_003.wav',\n",
       " 'p232_005.wav',\n",
       " 'p232_006.wav']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\\")[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
