{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugJNGnNlkTwI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import cmath\n",
    "\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "from keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(X, axis):\n",
    "    X2 = K.square(X)\n",
    "    M2 = K.sum(X2, axis=axis, keepdims=True)\n",
    "    return K.sqrt(M2)\n",
    "\n",
    "def Magnitude(X):\n",
    "    return layers.Lambda(magnitude, arguments={'axis':3})(X)\n",
    "\n",
    "\n",
    "def magnitude_loss(y_actual, y_predicted):\n",
    "    ya_magnitude = magnitude(y_actual,2)\n",
    "    yp_magnitude = magnitude(y_predicted,2)\n",
    "    mag_loss = K.mean(K.sum(K.square(ya_magnitude-yp_magnitude)))\n",
    "    component_loss = K.mean(K.sum(K.square(y_actual-y_predicted)))\n",
    "    return mag_loss + 0.5 * component_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'PrintV2' type=PrintV2>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.zeros((10,15,2))\n",
    "import tensorflow as tf\n",
    "tf.print(magnitude(t,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 1) [[[1.41421356]\n",
      "  [1.41421356]\n",
      "  [1.41421356]]\n",
      "\n",
      " [[1.41421356]\n",
      "  [1.41421356]\n",
      "  [1.41421356]]]\n",
      "2.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "def np_magnitude(X, axis):\n",
    "    X2 = np.square(X)\n",
    "    M2 = np.sum(X2, axis=axis, keepdims=True)\n",
    "    return np.sqrt(M2)\n",
    "\n",
    "def magnitude_loss(y_actual, y_predicted):\n",
    "    ya_magnitude = np_magnitude(y_actual,2)\n",
    "    yp_magnitude = np_magnitude(y_predicted,2)\n",
    "    print ()\n",
    "    mag_loss = np.mean(np.square(ya_magnitude-yp_magnitude))\n",
    "    #component_loss = K.mean(K.sum(K.square(y_actual-y_predicted)))\n",
    "    return mag_loss # + 0.5 * component_loss\n",
    "\n",
    "\n",
    "t = np.ones((2,3,2))\n",
    "z = np.zeros((2,3,2))\n",
    "M = np_magnitude(t,2)\n",
    "print(M.shape, M)\n",
    "\n",
    "print(magnitude_loss(t,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPWfsAnkkgxD"
   },
   "outputs": [],
   "source": [
    "# If on google colab, run this\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "os.chdir('drive/My Drive/Projects/Audio Separation/Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X4ZOOJsSkTwM"
   },
   "source": [
    "TODO\n",
    "* Clean out cqt stuff \n",
    "\n",
    "* Add regularizers and drop out\n",
    "\n",
    "* Use callbacks for LR reduction and to save best models with error info\n",
    "\n",
    "* Automatic logging of graphs, errors, models etc. for comparison\n",
    "* Add graph of model\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file='model.png')\n",
    "* Create log output function, then capture to text file (also export graphs?)\n",
    "\n",
    "* Look for sources of noise that are close to what I want?  Or generate some clips?\n",
    "\n",
    "* Debugging tools for comparing, listening to, and viewing clips\n",
    "* Add audio quality comparisons between clean clips and cleaned clips for evaluation\n",
    "\n",
    "* Add history error plotting to compare different learning models, topologies, etc.\n",
    "\n",
    "* Look into streaming frames to & from file and having way more samples\n",
    "\n",
    "* Why does https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785 only use real component?\n",
    "* Evaluate different representations of complex numbers in terms of learnability\n",
    "\n",
    "* Consider generating custom data for goal - male speakers, low voice, specific sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0NWhq04kTwN"
   },
   "outputs": [],
   "source": [
    "# Constants and settings\n",
    "WINDOW_SIZE = 25  # Has to be odd\n",
    "TARGET_COL = WINDOW_SIZE//2\n",
    "\n",
    "DTYPE = 'float32'\n",
    "\n",
    "# cqt related\n",
    "FFT_BINS = 513 # function of items below\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "# stft values\n",
    "N_FFT = 1024 # 512 recommended for speech, music typically 2048\n",
    "\n",
    "# cqt values\n",
    "#BINS_PER_OCTAVE = 12 * 10\n",
    "#FMIN = librosa.note_to_hz('C1')\n",
    "#OCTAVES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUhAB8HrkTwP"
   },
   "outputs": [],
   "source": [
    "# Idea here is that we operate on magnitude, and will just use phase from the original noisy sample\n",
    "\n",
    "def combine_target(t):\n",
    "    return (t[0:t.shape[0]//2] + 1j * t[t.shape[0]//2:]).reshape(1,(t.shape[0]//2))\n",
    "\n",
    "def rebuild_fft(output, original_fft):\n",
    "    vphase = np.vectorize(cmath.phase)\n",
    "    o_phase = vphase(original_fft)\n",
    "    mag = output.T\n",
    "    vrect = np.vectorize(cmath.rect)\n",
    "    return vrect(mag, o_phase)\n",
    "    \n",
    "# build up as (bins, samples) then transpose to model view of (samples, bins)\n",
    "def targets_to_fft(targets):\n",
    "    fft = np.empty((targets.shape[0],targets.shape[1]//2), dtype='complex64')\n",
    "    for i in range(0, targets.shape[0]):\n",
    "        fft[i] = combine_target(targets[i])\n",
    "    return fft.T   # transpose\n",
    "\n",
    "def get_ft(wav):\n",
    "    #c = librosa.cqt(wav, hop_length=HOP_LENGTH, fmin=FMIN, n_bins=OCTAVES*BINS_PER_OCTAVE, bins_per_octave=BINS_PER_OCTAVE)\n",
    "    c = librosa.stft(wav, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "    return c\n",
    "\n",
    "def inv_ft(ft):\n",
    "    #return librosa.icqt(ft, hop_length=HOP_LENGTH, bins_per_octave=BINS_PER_OCTAVE)\n",
    "    return librosa.istft(ft, hop_length=HOP_LENGTH)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bAXU2RkkTwX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_frames(data_path, samples):\n",
    "    frames_file = data_path + \"\\\\frames-\" + str(samples)\n",
    "    filename = os.fsdecode(frames_file)\n",
    "    return np.memmap(filename, mode='r', dtype=DTYPE, shape=(samples, FFT_BINS, WINDOW_SIZE, 1))\n",
    "\n",
    "def get_targets(data_path, samples):\n",
    "    targets_file = data_path + \"\\\\targets-\" + str(samples)\n",
    "    filename = os.fsdecode(targets_file)\n",
    "    return np.memmap(filename, mode='r', dtype=DTYPE, shape=(samples, FFT_BINS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mgM7ZVjlStg"
   },
   "outputs": [],
   "source": [
    "# For collab data\n",
    "frames = np.memmap(\"frames-10000\", mode='r', dtype=DTYPE, shape=(10000, FFT_BINS, WINDOW_SIZE, 1))\n",
    "targets = np.memmap(\"targets-10000\", mode='r', dtype=DTYPE, shape=(10000, FFT_BINS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HlE9DG3kTwb"
   },
   "outputs": [],
   "source": [
    "# For local PC data\n",
    "frames = get_frames(\"f://audiodata\", 10000)\n",
    "targets = get_targets(\"f://audiodata\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ur6yJmzVkTwc"
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "print(frames[i,0, 12:13, 0])\n",
    "print(targets[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibbfUgj5kTwf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Real model (eventually)\n",
    "ALPHA = 0.05\n",
    "L2Reg = 0.00000 # bumping this up to 0.000005 didn't seem very good\n",
    "\n",
    "inputs = layers.Input(shape=(FFT_BINS,WINDOW_SIZE,1)) # Full window\n",
    "\n",
    "def sub_samples(samples, n):\n",
    "    half_cut = (WINDOW_SIZE - n) // 2\n",
    "    print (half_cut)\n",
    "    return samples[:,:,half_cut:-half_cut,:]\n",
    "    \n",
    "# process inputs into subsets of interest\n",
    "input_slice = layers.Lambda(sub_samples, arguments = {'n':1}, name=\"targetslice\")(inputs)\n",
    "\n",
    "# Horizontal first - across bins then samples\n",
    "conv1 = layers.Conv2D(256, kernel_size=(FFT_BINS,3), activity_regularizer=regularizers.l2(L2Reg), name=\"conv1\")(inputs)\n",
    "c1a = layers.LeakyReLU(alpha=ALPHA)(conv1)\n",
    "convh2 = layers.Conv2D(128, kernel_size=(1,WINDOW_SIZE-2), activity_regularizer=regularizers.l2(L2Reg), name=\"convh2\")(c1a)\n",
    "ch2a = keras.layers.LeakyReLU(alpha=ALPHA)(convh2)\n",
    "flat_h = layers.Flatten(name=\"flat_h\")(ch2a)\n",
    "\n",
    "# Vertical features - across samples then bins\n",
    "conv3 = layers.Conv2D(128, kernel_size=(5,WINDOW_SIZE), activity_regularizer=regularizers.l2(L2Reg), name=\"conv3\")(inputs) \n",
    "c3a = layers.LeakyReLU(alpha=ALPHA)(conv3)\n",
    "#pool2 = layers.MaxPooling2D(pool_size=(8,1), strides=(4,1))(c3a)\n",
    "#p2a = layers.LeakyReLU(alpha=ALPHA)(pool2)\n",
    "conv4 = layers.Conv2D(48, kernel_size=(FFT_BINS-4,1), activity_regularizer=regularizers.l2(L2Reg), name=\"conv4\")(c3a)\n",
    "c4a = layers.LeakyReLU(alpha=ALPHA)(conv4)\n",
    "flat_v = layers.Flatten(name=\"flat_v\")(c4a)\n",
    "\n",
    "flat = layers.concatenate([flat_h, flat_v])\n",
    "\n",
    "flat_in = layers.Flatten()(input_slice)\n",
    "\n",
    "dense0 = layers.Dense(1500, activity_regularizer=regularizers.l2(L2Reg))(flat)\n",
    "d0a = layers.LeakyReLU(alpha=ALPHA)(dense0)\n",
    "merge1 = layers.concatenate([d0a, flat_in])\n",
    "dense1 = layers.Dense(1300, activity_regularizer=regularizers.l2(L2Reg))(merge1)\n",
    "d1a = keras.layers.LeakyReLU(alpha=ALPHA)(dense1)\n",
    "#dense2 = layers.Dense(500, )(dense1)\n",
    "#d2a = keras.layers.LeakyReLU(alpha=ALPHA)(dense2)\n",
    "merged = layers.concatenate([d1a, flat_in])\n",
    "outputs = layers.Dense(FFT_BINS, activation='linear')(merged)\n",
    "\n",
    "model = keras.models.Model(inputs=[inputs], outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mcieWulkTwh",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=15, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "save_best = keras.callbacks.ModelCheckpoint(\"Best_model.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "hist = model.fit([frames], targets, epochs=10, callbacks = [stopper, save_best], batch_size=128, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqG_dSiTkTwj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = hist\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.ylim((0, 2 * history.history['loss'][0])) # because sometimes there are stupid spikes in error\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('test.png')\n",
    "print(\"Validation loss mean 5+ epochs {0:.4}\".format(np.mean(history.history['val_loss'][5:])))\n",
    "print(\"Lowest validation loss {0:.4}\".format(np.min(history.history['val_loss'][5:])))\n",
    "print(\"Frames \", frames.shape[0])\n",
    "\n",
    "#Add verification means for 1-10, 11-20, 21-30?  Or slope for different ranges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tuZ62OokTwl"
   },
   "outputs": [],
   "source": [
    "# Not required because of 'restore best weights'\n",
    "#model = keras.models.load_model(\"Best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lCNToBxkTwR"
   },
   "outputs": [],
   "source": [
    "# some test data to hack around with\n",
    "test_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\p232_010.wav\"\n",
    "wav, rate = librosa.core.load(test_file)\n",
    "fft = get_ft(wav)\n",
    "#print(fft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8DZfaSgkTwn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Full round trip test\n",
    "file = \"p232_001.wav\"\n",
    "\n",
    "verify_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\\" + file\n",
    "clean_file = \"Assets\\\\DataShareArchive\\\\Test\\\\Clean\\\\\" + file\n",
    "\n",
    "def clean_clip(model, n_file):\n",
    "    verify_frames = clip_frames(n_file)\n",
    "    output_targets = model.predict([verify_frames, verify_frames[:,:,TARGET_COL:TARGET_COL+1,:]])\n",
    "    wav, rate = librosa.core.load(n_file)\n",
    "    n_fft = get_ft(wav)\n",
    "    fft = rebuild_fft(output_targets, n_fft)\n",
    "    return fft, inv_ft(fft)\n",
    "\n",
    "p_fft, p_wav = clean_clip(model, verify_file)\n",
    "    \n",
    "wav, rate = librosa.core.load(clean_file)\n",
    "c_fft = get_ft(wav)\n",
    "\n",
    "\n",
    "def display_fft(ft):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "print(\"Cleaned clip\")\n",
    "\n",
    "err_fft = c_fft - p_fft\n",
    "print(\"Average abs err vs clean = \", np.mean(abs(err_fft)))\n",
    "\n",
    "display_fft(p_fft)\n",
    "Audio(p_wav,rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqHS_31nkTwp"
   },
   "outputs": [],
   "source": [
    "def draw(wav):\n",
    "    fft = librosa.stft(wav, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "    return fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xhtGoYOkTwr"
   },
   "outputs": [],
   "source": [
    "wav, rate = librosa.core.load(verify_file)\n",
    "n_fft = draw(wav)\n",
    "\n",
    "print(\"Noisy file\")\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeyY6RDTkTwu"
   },
   "outputs": [],
   "source": [
    "wav, rate = librosa.core.load(clean_file)\n",
    "c_fft = draw(wav)\n",
    "\n",
    "print(\"Clean sample\")\n",
    "Audio(wav, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zO4WwsB9kTww"
   },
   "outputs": [],
   "source": [
    "cut_fft = n_fft-p_fft\n",
    "display_fft(cut_fft)\n",
    "\n",
    "print(\"Removed audio\")\n",
    "print(\"Average cut value = \", np.mean(abs(cut_fft)))\n",
    "\n",
    "cut_wav = inv_ft(cut_fft)\n",
    "Audio(cut_wav,rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tC3WpzokTwy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7wCtwF4kTw0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%capture cap\n",
    "print(model.summary())\n",
    "#with open('output.txt', 'w') as f:\n",
    "#    f.write(cap.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0b_mGnNZkTw3"
   },
   "outputs": [],
   "source": [
    "fresh_wav, rate = librosa.core.load(\"Assets\\\\DataShareArchive\\\\Test\\\\Noisy\\\\p232_019.wav\")\n",
    "Audio(fresh_wav, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peLEO0VZkTw6"
   },
   "source": [
    "Test & reference stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPX3_ZiMkTw7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ft = clip_frames(test_file)\n",
    "tt = clip_targets(test_file)\n",
    "\n",
    "print(ft.shape)\n",
    "print(tt.shape)\n",
    "\n",
    "#Frame / target check  -  don't use first row because it might be zeroed out\n",
    "r = 10\n",
    "print(tt[0,r])\n",
    "print(ft[0,r,TARGET_COL:TARGET_COL+1,0])\n",
    "\n",
    "# Round trip test\n",
    "new_fft = rebuild_fft(tt, fft)\n",
    "print(new_fft.shape)\n",
    "new_wav = inv_ft(new_fft)\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "Audio(new_wav,rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k67NuIJQkTw-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "def show_fft(wav):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(librosa.stft(wav)), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "def display_fft(ft):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(new_fft), ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "print(new_fft.shape)\n",
    "\n",
    "#show_fft(wav)\n",
    "#show_fft(new_wav)\n",
    "#Audio(wav, rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4HRcM0rkTxA"
   },
   "outputs": [],
   "source": [
    "# Test stuff for hacking around    \n",
    "    \n",
    "a = np.array([[1+2j, 3+4j, 1.5+2.5j],[5+6j,7+8j, 5.5+6.5j]])\n",
    "print(a)\n",
    "a1 = a[0]\n",
    "print(a1)\n",
    "ar = a1.real\n",
    "ai = a1.imag\n",
    "\n",
    "st = np.zeros((6))\n",
    "st[0:3] = ar\n",
    "st[3:6] = ai\n",
    "print(ar.shape, ai.shape, st.shape)\n",
    "print(ar, ai)\n",
    "print(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lofx2hiEkTxC"
   },
   "outputs": [],
   "source": [
    "# ''do nothing' model that should be able to guess outputs from outputs\n",
    "\n",
    "inputs = layers.Input(shape=(FFT_BINS*2,))\n",
    "dense1 = layers.Dense(2000, activation='relu')(inputs)\n",
    "dense2 = layers.Dense(2000, activation='relu')(dense1)\n",
    "#flat = layers.Flatten()(dense)\n",
    "#flat_in = layers.Flatten()(inputs)\n",
    "#merged = layers.concatenate([flat, flat_in])\n",
    "merged = layers.concatenate([dense2, inputs])\n",
    "linear = layers.Dense(2000, activation='linear')(merged)\n",
    "outputs = layers.Dense(2*FFT_BINS, activation='linear')(linear)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "model.fit(targets, targets, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_Sx3KigkTxD"
   },
   "outputs": [],
   "source": [
    "t = layers.Input(shape=(10,))\n",
    "t1 = layers.Dense(100)(t)\n",
    "o = keras.layers.LeakyReLU(alpha=0.3)(t1)\n",
    "m = keras.models.Model(inputs=t, outputs=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tPbIQ8uakTxH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Real model (eventually)\n",
    "ALPHA = 0.05\n",
    "\n",
    "inputs = layers.Input(shape=(FFT_BINS,WINDOW_SIZE,1)) # Full window\n",
    "input_slice = layers.Input(shape=(FFT_BINS,1,1)) # Just the center row that we're trying to predict\n",
    "\n",
    "# Horizontal features - across bins\n",
    "conv1 = layers.Conv2D(256, kernel_size=(FFT_BINS,3))(inputs)\n",
    "c1a = keras.layers.LeakyReLU(alpha=ALPHA)(conv1)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(1,6), strides=(1,3))(c1a)\n",
    "p1a = keras.layers.LeakyReLU(alpha=ALPHA)(pool1)\n",
    "flat_h = layers.Flatten()(p1a)\n",
    "\n",
    "# Vertical features - across samples\n",
    "conv3 = layers.Conv2D(128, kernel_size=(5,WINDOW_SIZE))(inputs) \n",
    "c3a = keras.layers.LeakyReLU(alpha=ALPHA)(conv3)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(6,1), strides=(3,1))(c3a)\n",
    "p2a = keras.layers.LeakyReLU(alpha=ALPHA)(pool2)\n",
    "conv4 = layers.Conv2D(48, kernel_size=(10,1), strides=(3,1))(p2a)\n",
    "c4a = keras.layers.LeakyReLU(alpha=ALPHA)(conv4)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(3,1), strides=(2,1))(c4a)\n",
    "p3a = keras.layers.LeakyReLU(alpha=ALPHA)(pool3)\n",
    "flat_v = layers.Flatten()(p3a)\n",
    "#flat = layers.Flatten()(conv4)\n",
    "\n",
    "flat = layers.concatenate([flat_h, flat_v])\n",
    "\n",
    "dense0 = layers.Dense(700)(flat)\n",
    "d0a = keras.layers.LeakyReLU(alpha=ALPHA)(dense0)\n",
    "#dense1 = layers.Dense(1000)(dense0)\n",
    "#d1a = keras.layers.LeakyReLU(alpha=ALPHA)(dense1)\n",
    "#dense2 = layers.Dense(500, )(dense1)\n",
    "#d2a = keras.layers.LeakyReLU(alpha=ALPHA)(dense2)\n",
    "flat_in = layers.Flatten()(input_slice)\n",
    "merged = layers.concatenate([d0a, flat_in])\n",
    "outputs = layers.Dense(FFT_BINS, activation='linear')(merged)\n",
    "\n",
    "model = keras.models.Model(inputs=[inputs,input_slice], outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NN Audio Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
